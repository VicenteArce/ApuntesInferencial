---
title: "Lecturas 1-10"
output: html_document
date: "2024-11-09"
---

```{r setup, include=FALSE}
library(dplyr)
library(ggpubr)
library(psych)
```
# Lectura 1 y 2 

## Enunciado

Sabemos que uno de los uso de los modelos estadísticos es describir o caracterizar un conjunto de datos, lo que aprendimos en la enseñanza secundaria y en cursos anteriores con el nombre de estadística descriptiva. Son muchas las herramientas, pero es importante saber usar la que es adecuada para lo que se quiere describir.

En este contexto trabajaremos con una selección de datos públicos recopilados por la encuesta CASEN 2017 en la Región Metropolitana (RM). La Encuesta CASEN es un estudio que mide la situación socioeconómica de los hogares en el país. Se realiza periódicamente y permite obtener datos sobre pobreza, ingresos, acceso a servicios básicos, educación, salud, y más, lo que ayuda a diseñar políticas públicas y programas sociales. La siguiente tabla detalla las variables seleccionadas:

Descripción de los datos
Variable	Descripción

folio	Identificador del hogar.

o	Número de orden de la persona dentro del hogar.

id.vivienda	Identificación de la vivienda.

hogar	Identificación del hogar en la vivienda.

region	Nombre de la región de Chile donde se ubica la vivienda (solo “Región Metropolitana de Santiago” en esta selección de datos).

provincia	Nombre de la provincia donde se ubica la vivienda (solo las 6 provincias de la RM en esta selección de datos).

comuna	Nombre de la comuna donde se ubica la vivienda (solo las 52 comunas de la RM en esta selección de datos).

ing.comuna	Posición en el ranking histórico del ingreso de la comuna (ascendente).

zona	Área geográfica (“Rural”, “Urbano”).

sexo	Sexo de la persona encuestada (“Hombre”, “Mujer”).

edad	Edad de la persona encuestada.

ecivil	Estado civil de la persona encuestada (8 posibles valores).

ch1	Situación ocupacional de la persona encuestada (4 posibles valores).

ytot	Ingreso total (en pesos)

Para este ejercicio se pide realizar las siguientes actividades:

Formar un equipo de 3 personas que cuente con al menos un computador con el entorno R instalado.
Obtener el archivo de datos desde la carpeta compartida para este ejercicio.

Considerar la pregunta asignada a su equipo. Discutir y consensuar qué medidas estadísticas (media, mediana, moda, etc.) y qué forma gráfica ayudaría a responder la pregunta asignada.

Construir un script en R que produzca los estadísticos y el gráfico seleccionado.

Documentar en el script el objetivo de cada estadístico, una descripción de lo que se ve en el gráfico y la respuesta a la pregunta planteada.
```{r}
src_dir <- "~/Downloads"
src_basename <- "EP01 Datos Casen 2017.csv"
src_file <- file.path(src_dir, src_basename)

datos <- read.csv2(src_file, stringsAsFactors = TRUE)

datos[["ytot"]] <- datos[["ytot"]] / 1000
```
### Análisis de frecuencias

#### ¿Se encuestaron más o menos la misma cantidad de gente en cada provincia de la RM?

Para responder a esta pregunta, debemos revisar las frecuencias y/o proporciones de personas encuestadas por provincia. Si estas se parecen, entonces la respuesta sería positiva, y en caso contrario, negativa.

```{r}
tabla_provincias <- as.data.frame(table(datos[["provincia"]]))
colnames(tabla_provincias) <- c("Provincia", "Frecuencia")
prop_provincias <- tabla_provincias[["Frecuencia"]] / sum(tabla_provincias[["Frecuencia"]]) * 100
tabla_provincias[["Prop."]] <- round(prop_provincias, 1)

cat("Encuestados por provincia:\n")
print(tabla_provincias)
```
Para reportar visualmente frecuencias o proporciones, podríamos utilizar un gráfico de torta. Pero si la intención del gráfico es comparar o contrastar estas frecuencias o proporciones, es más adecuado usar un gráfico de barras. Generemos este gráfico para las frecuencias:

```{r}
# Construir gráfico de barras.
g_barra1 <- ggbarplot(tabla_provincias, x = "Provincia", y = "Frecuencia",
                      label = TRUE, lab.pos = "out", lab.col = "black",
                      fill = "Provincia", palette = "jco",
                      title = "Encuestados en la RM por provincia"
                     )
g_barra1 <- g_barra1 + rotate_x_text(angle = 45)
print(g_barra1)
```
En el gráfico podemos ver con claridad que la cantidad de personas encuestadas es mucho mayor en la provincia de Santiago. La tabla de encuestados por provincia nos informa que esta provincia representa más del 75% del total. Escribamos la conclusión

La encuesta CASEN 2017no fue aplicada a la misma cantidad de gente en cada provincia de la Región Metropolitana. La provincia de Santiago concentra la mayoría de las encuestras (3/4 partes). Las otras provincias representan entre 3,5% y 6,3%.

### Análisis de una variable númerica

#### ¿Cómo podemos describir el ingreso de las chilenas y los chilenos de la RM?

Para responder a esta pregunta, primero debemos decir que el ingreso, medidos en miles de pesos en nuestros datos, puede considerarse como una variable continua que es redondeada por conveniencia. Por ejemplo, aunque una persona deba recibir $372.313,23456¯¯¯
 de comisión por las ventas que hizo en el mes, es probable que su empleadora le pague $372.313
.

Tenemos varias alternativas de gráficos para representar una variable continua. Por ejemplo, podríamos usar un diagrama de cajas, un diagrama de puntos, un diagrama de densidad o un histograma. Esta última es probablemente la alternativa más usada para explorar la forma en que se distribuyen los. Generemos estos gráficos con los datos de ingreso, marcando la media en cada uno de ellos.

```{r}
# Construir gráfico de barras.
g_barra1 <- ggbarplot(tabla_provincias, x = "Provincia", y = "Frecuencia",
                      label = TRUE, lab.pos = "out", lab.col = "black",
                      fill = "Provincia", palette = "jco",
                      title = "Encuestados en la RM por provincia"
                     )
g_barra1 <- g_barra1 + rotate_x_text(angle = 45)
print(g_barra1)
```

Los gráficos nos muestran que la variable ingreso presenta una distribución muy asimétrica con valores atípicos (outliers) muy altos. Pero debemos observar que pareciera haber muchas observaciones alrededor del valor cero. Esto nos debería hacer dudar de que nuestros gráficos están correctos. Miremos un poco los datos:

```{r}
cat("Ingreso promedio por situación ocupacional:\n")
print(datos |> group_by(ch1) |> summarise(ingreso_medio = mean(ytot), n = n()))
```

Evidentemente estamos cometiendo un error al considerar todos los datos, pues en las encuestas existe un número importante de menores de edad, que uno esperaría no tuvieran ingresos. Quitemos estos datos de nuestros gráficos.

```{r}
datos_2 <- datos |> filter(edad >= 18)

# Diagrama de cajas
g_boxplot2 <- ggboxplot(datos_2, x = NULL, y = "ytot",
                        color = "#6D9EC1", fill = "#BFD5E3",
                        add = "mean", add.params = list(color = "#FC4E07"),
                        title = "Ingreso en la RM",
                        xlab = " ", ylab = "Ingreso total (miles de pesos)")
g_boxplot2 <- g_boxplot2 + rremove("x.text")
g_boxplot2 <- g_boxplot2 + rremove("x.ticks")

# Diagrama de puntos (1 punto = 2.600 observaciones)
g_puntos2 <- ggdotplot(datos_2, y = "ytot", binwidth = 2600,
                       color = "#6D9EC1", fill = "#BFD5E3",
                       add = "mean", add.params = list(color = "#FC4E07"),
                       title = "Ingreso en la RM",
                       xlab = " ", ylab = "Ingreso total (miles de pesos)")
g_puntos2 <- g_puntos2 + rremove("x.text")
g_puntos2 <- g_puntos2 + rremove("x.ticks")

# Diagrama de densidad
g_densi2 <- ggdensity(datos_2, x = "ytot",
                      color = "#6D9EC1", fill = "#BFD5E3",
                      add = "mean", add.params = list(color = "#FC4E07"),
                      title = "Ingreso en la RM",
                      xlab = "Ingreso total (miles de pesos)", ylab = "Densidad")

# Histograma
g_hist2 <- gghistogram(datos_2, x = "ytot", bins = 15,
                       color = "#6D9EC1", fill = "#BFD5E3",
                       add = "mean", add.params = list(color = "#FC4E07"), rug = TRUE,
                       title = "Ingreso en la RM",
                       xlab = "Ingreso total (miles de pesos)", ylab = "Frecuencia")

# Juntamos los gráficos
g2 <- ggarrange(g_boxplot2, g_puntos2, g_densi2, g_hist2, ncol = 2, nrow = 2)
print(g2)
```

¡Ah! No parece haber un cambio importante en los gráficos que siguen indicando que el ingreso en Chile se distribuye muy asimétricamente, con uno pocas observaciones con valores muy altos. Esto hace que las medidas, como la media, se distorcionen, por lo que es mejor usar otras medidas de tendencia central más robustas, tales como la mediana, el rango intercuartil o la media truncada (en inglés, trimmed mean). Veamos estas estadísticas.

```{r}
cat("Estadísticas del ingreso de mayores de edad en Chile:\n")
describe(datos_2[["ytot"]], skew = FALSE, IQR = TRUE, quant = c(0.25, 0.75, 0.9))
```

Podemos ver que, mientras el ingreso medio de los mayores de edad de la RM es de aproximadamente $655 mil, la mitad de los encuestados (i.e. la mediana) consigue menos de $368 mil, 3/4 partes menos de $650 mil, y el 90% de los encuestados consigue menos de $1 millón 400 mil.

Mejoremos la vista que tenemos de los gráficos con estos datos.

```{r}
# Hacemos una especie de 'zoom' al 90% inferior de las observaciones
g_boxplot2 <- ggpar(g_boxplot2, ylim = c(0, 1400))
g_puntos2 <- ggpar(g_puntos2, ylim = c(0, 1400))
g_densi2 <- ggpar(g_densi2, xlim = c(0, 1400))
g_hist2 <- ggpar(g_hist2, ylim = c(0, 1400))

# Juntamos los gráficos
g2 <- ggarrange(g_boxplot2, g_puntos2, g_densi2, g_hist2, ncol = 2, nrow = 2)
print(g2)
```

Y actualicemos las estadísticas.

```{r}
datos_2 <- datos_2 |> filter(ytot <= 1400) |> droplevels()

cat("Estadísticas del 90% inferior del ingreso de mayores de edad en Chile:\n")
describe(datos_2[["ytot"]], skew = FALSE, IQR = TRUE, quant = c(0.25, 0.75))
```

Estamos en condiciones de concluir.
Los ingresos en Chile (en el año 2017) se distribuyen con una fuerte asimetría positiva. Así, la mayoría de la población tiene ingresos bajos (75% de la población obtiene menos de $650 mil y el 90% menos de $1 millón 400 mil), mientras que un grupo minoritario obtiene ingresos mucho mayores.

### Análisis de una variable númerica en dos grupos distintos

#### ¿Tienen hombres y mujeres ingresos similares?

En este caso podemos usar los mismos gráficos que en el ejemplo anterior, pero mostrando cada grupo por separado. Para esto podemos usar la variable categórica (o factor, en jerga estadística) sexo para, por ejemplo, asignar el color del gráfico. Del ejercicio anterior recatamos que el diagrama de cajas y el de densidad nos podría ayudar a comparar dónde se encuentra la masa de cada grupo, y enfocarnos en el 90% de las observaciones de los mayores de edad. Generemos estos gráficos.

```{r}
# Diagrama de cajas
g_boxplot3 <- ggboxplot(datos_2, x = "sexo", y = "ytot",
                        color = "sexo", fill = "sexo", palette = "jco", 
                        add = "mean", add.params = list(color = "#FC4E07"),
                        title = "Ingreso en la RM por sexo",
                        xlab = "Sexo", ylab = "Ingreso total (miles de pesos)")

# Diagrama de densidad
g_densi3 <- ggdensity(datos_2, x = "ytot",
                      color = "sexo", fill = "sexo", palette = "jco",
                      add = "mean", add.params = list(color = "#FC4E07"),
                      title = "Ingreso en la RM por sexo",
                      xlab = "Ingreso total (miles de pesos)", ylab = "Densidad")

# Juntamos los gráficos
g3 <- ggarrange(g_boxplot3, g_densi3, ncol = 2, nrow = 1)
print(g3)
```

Vemos que se mantiene la asimetría en ambos grupos. Obtengamos las estadísticas descriptivas, teniendo cuidado de no usar las medidas poco robustas (como la media y la desviación estándar).

```{r}
h <- describe(datos_2[datos_2[["sexo"]] == "Hombre", "ytot"], skew = FALSE, IQR = TRUE, quant = c(0.25, 0.75))
m <- describe(datos_2[datos_2[["sexo"]] == "Mujer", "ytot"], skew = FALSE, IQR = TRUE, quant = c(0.25, 0.75))
estads_3 <- rbind(h, m)
rownames(estads_3) <- c("Hombre", "Mujer")

cat("Estadísticas enfocadas del ingreso por sexo:\n")
print(estads_3)
```
Podemos concluir.
La fuerte asimetría positiva de los ingresos en Chile se observa en ambos sexos. Sin embargo, las mujeres tienen ingresos algo más bajos que los hombres.

### Análisis de una variable númerica en más de dos grupos distintos
#### ¿Son similares los ingresos registrados en las diferentes provincias de la RM?

El análisis para responder esta pregunta es muy similar al de la pregunta precedente, aunque ahora tenemos una variable categórica con más de dos niveles (más de dos grupos). La construcción del gráfico es idéntica.

```{r}
# Diagrama de cajas
g_boxplot4 <- ggboxplot(datos_2, x = "provincia", y = "ytot",
                        color = "provincia", fill = "provincia", palette = "jco",
                        add = "mean", add.params = list(color = "#FC4E07"),
                        title = "Ingreso en la RM por provincia",
                        xlab = "Sexo", ylab = "Ingreso total (miles de pesos)")
g_boxplot4 <- g_boxplot4 + rotate_x_text(angle = 45)

# Diagrama de densidad
g_densi4 <- ggdensity(datos_2, x = "ytot",
                      color = "provincia", fill = "provincia", palette = "jco",
                      add = "mean", add.params = list(color = "#FC4E07"),
                      title = "Ingreso en la RM por provincia",
                      xlab = "Ingreso total (miles de pesos)", ylab = "Densidad")

# Juntamos los gráficos
g4 <- ggarrange(g_boxplot4, g_densi4, ncol = 2, nrow = 1)
print(g4)
```

Lo mismo pasa con las estadísticas descriptivas.

```{r}
provincias <- levels(datos_2[["provincia"]])
prov1 <- describe(datos_2[datos_2[["provincia"]] == provincias[1], "ytot"], skew = FALSE, IQR = TRUE, quant = c(0.25, 0.75))
prov2 <- describe(datos_2[datos_2[["provincia"]] == provincias[2], "ytot"], skew = FALSE, IQR = TRUE, quant = c(0.25, 0.75))
prov3 <- describe(datos_2[datos_2[["provincia"]] == provincias[3], "ytot"], skew = FALSE, IQR = TRUE, quant = c(0.25, 0.75))
prov4 <- describe(datos_2[datos_2[["provincia"]] == provincias[4], "ytot"], skew = FALSE, IQR = TRUE, quant = c(0.25, 0.75))
prov5 <- describe(datos_2[datos_2[["provincia"]] == provincias[5], "ytot"], skew = FALSE, IQR = TRUE, quant = c(0.25, 0.75))
prov6 <- describe(datos_2[datos_2[["provincia"]] == provincias[6], "ytot"], skew = FALSE, IQR = TRUE, quant = c(0.25, 0.75))
estads_4 <- rbind(prov1, prov2, prov3, prov4, prov5, prov6)
rownames(estads_4) <- provincias

cat("Estadísticas enfocadas del ingreso por provincia:\n")
print(estads_4)
```

Hagamos una conclusión con esta información.
Los ingresos de la población adulta de cada provincia de la RM muestra una fuerte asimetría positiva. Si bien no hay grandes diferencias entre ellas, los ingresoslas en las provincias de Talagante y Melipilla se concentran en rangos levemente más bajos (aproximadamente $146 mil a $467 mil y $140 mil a $400 mil, respectivamente), mientras que la provincia de Santiago muestra rangos levemente superiores (de $189 mil a $552 mil aproximadamente).


### Análisis de dos variables númericas

#### ¿Tiene relación el ingreso con la riqueza del municipio donde se habita?

En este caso, queremos ver si una variable numérica se corelaciona con otra variable (también numérica). Es decir

si una variable crece, ¿la otra también?
o bien, si una variable crece, ¿la otra disminuye?
o tal vez no hay relación, es decir, las variables son independientes.
Una herramienta adecuada para abordar este tipo de preguntas es el gráfico de dispersión. Generemos el gráfico para este análisis, nuevamente enfocado en la población adulta con ingresos hasta $1 millón 400 mil (90% de las observaciones).

```{r}
g_disp5 <- ggscatter(datos_2, x = "ing.comuna", y = "ytot",
                    color = "#6D9EC1", fill = "#BFD5E3", size = 0.5,
                    title = "Relación ingreso - riqueza de la comuna en la RM",
                    ylab = "Ingreso total (miles de pesos)",
                    xlab = "Ranking de riqueza (ascendente)")
print(g_disp5)
```

Parece haber un incremento en el número de personas con ingresos altos a medida que aumenta el ranking de la riqueza de la comuna.

En el curso anterior, aprendimos que un estadístico para medir la fuerza de la relación entre dos variables numéricas era el coeficiente de correlación de Pearson. También vimos que podemos revisar una línea de regresión entre las variables. Agreguemos esta información al gráfico.

```{r}
g_disp5 <- g_disp5 + stat_smooth(formula = y ~ x, method = "lm", color = "#FC4E07")
g_disp5 <- g_disp5 + stat_cor(aes(label = after_stat(r.label)), method = "pearson",
                              color = "#FC4E07", r.digits = 3, label.y = 1450)
print(g_disp5)
```

Podemos concluir.
Existe una relación positiva entre el ingreso de las personas y el ranking de riqueza de la comuna, aunque esta es débil (R=0,23
).

Nota: debemos mencionar que el coeficiente de correlación de Pearson es una medida sensible a valores atípicos o distribuciones asimétricas, por lo que no debería utilizase con estos datos. Se podría usar una alternativa más robusta, como el coeficiente de correlación ρ
 de Spearman (indicando method = "spearman" al agregar la estadística al gráfico) o el coeficiente τ
 de Kendall (con method = "kendall").
 
### Análisis de dos variables númericas en grupos distintos

#### ¿Van los ingresos de las y los chilenos incrementándose con la experiencia y de forma similar entre hombres y mujeres?

Procedemos en forma similar a la pregunta anterior, pero ahora separamos los diferentes grupos por colores. Construyamos el gráfico, agregando desde un comienzo las líneas de regresión.

```{r}
g_disp6 <- ggscatter(datos_2, x = "edad", y = "ytot",
                    color = "sexo", fill = "sexo", size = 0.5,
                    add = "reg.line", add.params = list(color = "#FC4E07"),
                    title = "Relación ingreso - edad por sexo",
                    ylab = "Ingreso total (miles de pesos)",
                    xlab = "Edad")
print(g_disp6)
```

Es difícil ver el gráfico. Parece haber una disminución de los ingresos a medida que se envejece. Pero esta podría ser solo una impresión, puesto que el número de personas encuestadas va disminuyendo con la edad, especialmente después de los 75 años. Para tener una mejor perspectiva, solo consideremos personas menores a la edad de jubilación. Además, separemos por sexo e indiquemos el coeficiente de correlación en cada caso.

```{r}
datos_3 <- datos_2 |> filter(sexo == "Hombre" & edad <= 65 | sexo == "Mujer" & edad <= 60) |> droplevels()

g_disp6 <- ggscatter(datos_3, x = "edad", y = "ytot",
                    color = "sexo", fill = "sexo", size = 0.5,
                    add = "reg.line", add.params = list(color = "#FC4E07"),
                    title = "Relación ingreso - edad por sexo",
                    ylab = "Ingreso total (miles de pesos)",
                    xlab = "Edad")
g_disp6 <- g_disp6 + stat_cor(aes(label = after_stat(r.label)), method = "pearson",
                              color = "#FC4E07", r.accuracy = 0.001, label.y = 1450)
g_disp6 <- g_disp6 + facet_wrap(~ sexo)
print(g_disp6)
```

Vemos que la relación cambia completamente (¿caerán los ingresos después de la edad de jubilación?). Saquemos conclusiones con esta información.
Existe una muy débil relación positiva (R=−0,116
) entre el ingreso de los hombres y su edad, es decir, sus ingresos tienden a ir subiendo a medida que se hacen mayores. En cambio no parece existir relación (R=−0,046
) entre la edad de las mujeres y el ingreso que perciben, que se mantiene prácticamente constante en durante toda la edad productiva legal.

# Lectura 3: Z test y T test

## Enunciado

Los intervalos de confianza y la capacidad de conocer la forma de la distribución muestral de los modelos estadísticos más simples, como las medias y las proporciones, nos permite, poner a prueba una hipótesis sobre el valor del parámetro en la población. Esto lo hicimos en el curso pasado, y aquí queremos recordarlo y aclarar los procedimientos y el funcionamiento de las herramientas en R para realizarlos.

Trabajaremos con el siguiente estudio: el Comité Olímpico de una gran potencia del atletismo está estudiando el programa de entrenamiento de varones para la competencia de 100 metros planos, por lo que ha recopilado datos de una muestra aleatoria de atletas. La siguiente tabla detalla las variables registradas en este estudio.
Descripción de los datos

Variable	Descripción
Id	Identificador único para cada atleta.

Raza	Raza del atleta (categórica: Blanca, Negra, Oriental).

Previo	Mejor tiempo registrado por el atleta antes de ingresar al programa de entrenamiento (numérica, en segundos).

Posterior	Mejor tiempo registrado por el atleta después de los primeros 6 meses del programa de entrenamiento (numérica, en segundos).

En el contexto de este estudio, realizaremos las siguientes actividades:

Obtener, desde el directorio compartido para este ejercicio práctico, el conjunto de datos recolectado.

Copiar los enunciados de los problemas asignados como comentarios de un script R.
Proponer una hipótesis nula y una hipótesis alternativa para cada caso.

Escribir código R para verificar que se cumplen las condiciones necesarias para docimar las hipótesis con las pruebas seleccionadas.

Escribir código R para realizar las pruebas de hipótesis seleccionadas.
Redactar respuestas a las preguntas planteadas (comentarios) en base a los resultados del análisis realizado.

```{r}
src_dir <- "~/Downloads"
src_basename <- "EP02 Datos.csv"
src_file <- file.path(src_dir, src_basename)

datos <- read.csv2(src_file, stringsAsFactors = TRUE)
```

### Pregunta 1 : El Comité Olímpico cree que el mejor tiempo medio de los atletas de raza blanca después de ingresar al programa de entrenamiento es superior a 17,23 segundos. ¿Soportan los datos esta afirmación?

En este caso, debemos inferir acerca de la población de atletas de raza blanca que no han pasado por el entrenamiento. Filtramos los datos para obtener los necesitados.

```{r}
datos_1 <- datos |>  filter(Raza == "Blanca") |> pull(Previo)
n_1 <- length(datos_1)

cat("Tamaño de la muestra:", n_1, "\n")
```

Como la muestra es pequeña (menos de 30 observaciones) y no conocemos la desviación estándar de la población, sería adecuado usar la prueba t de Student para una muestra. Pero antes debemos verificar las condiciones.

Como se trata de 26 atletas diferentes, la muestra fue seleccionada de manera aleatoria y representa menos del 10% de todos los atletas varones de raza blanca, podemos asumir que las observaciones son independientes entre sí.

Ahora debemos verificar si las observaciones presentan una distribución cercana a la normal. Una forma de hacer esto es mediante la prueba de normalidad de Shapiro-Wilk.

```{r}
normalidad_1 <- shapiro.test(datos_1)

cat("Comprobación de la normalidad de los datos:\n")
print(normalidad_1)
```

Puesto que el estadístico obtenido (W=0,977
) nos lleva a un valor p alto (p=0,793
), no podemos descartar que la muestra proviene de una distribución normal, por lo que podemos aplicar la prueba seleccionada.

Como no hay indicios de que tengamos que ser cautelosos con los resultados, fijamos el nivel de significación en α=0,05
. Ahora debemos formular las hipótesis:

H0
: antes del entrenamiento, la media de las mejores marcas de los atletas de raza blanca (μantesB
) en 100 metros planos es de 17,23 segundos (μantesB=17,23
 [s]).

HA
: antes del entrenamiento, la media de las mejores marcas de los atletas de raza blanca en 100 metros planos es distinta de 17,23 segundos (μantesB≠17,23
 [s]).

Efectuamos la prueba con estas condiciones

```{r}
alfa_1 <- 0.05
valor_nulo_1 <- 17.23

prueba_1 <- t.test(datos_1, alternative = "two.sided", mu = valor_nulo_1, conf.level = 1 - alfa_1)

cat("Prueba de hipótesis pregunta 1:\n")
print(prueba_1)
```
Ahora debemos interpretar lo que nos dice la prueba realizada.
La verdadera media de las mejores marcas de atletas de raza blanca antes de entrar al programa de entrenamiento es distinta de 17,23 [s] (t(25)=4,517;p<0,001
). Con 95% de confianza se encuentra en el intervalo [16,100;16,808]
.

### Pregunta 2: ¿Sugieren los datos que en promedio la mejor marca de los atletas de raza oriental se reduce en menos de 6,45 segundos tras el entrenamiento?

En este caso, debemos inferir acerca de las medias de dos muestras apareadas, es decir sobre el valor de la media de las diferencias de los pares de observaciones. Obtengamos las muestras con las que trabajaremos y sus tamaños (que es el mismo para ambas, al estar pareadas).

```{r}
datos_2_ant <- datos |> filter(Raza == "Oriental") |> pull("Previo")
datos_2_pos <- datos |> filter(Raza == "Oriental") |> pull("Posterior")
n_2 <- length(datos_2_ant)

cat("Tamaño de la muestra:", n_2, "\n")
```

Como la muestra es pequeña (menos de 30 observaciones) y no conocemos la desviación estándar de la población, sería adecuado usar la prueba t de Student para dos muestras apareadas. Pero antes debemos verificar las condiciones.

Como se trata de 27 atletas diferentes seleccionados aleatoriamente, menor al 10% de la población, podemos suponer que los pares de observaciones son independientes entre sí.

Ahora debemos verificar si las diferencias presentan una distribución cercana a la normal. Una forma de hacer esto es mediante un gráfico Q-Q.

```{r}
datos_2_difs <- datos_2_ant - datos_2_pos
g_qq2 <- ggqqplot(data.frame(dif = datos_2_difs), x = "dif",
                  color = "#6D9EC1", fill = "#BFD5E3",
                  add = "sd", #add.params = list(color = "#FC4E07"),
                  title = "Gráfico Q-Q de las diferencias observadas",
                  xlab = " ", ylab = "Tiempo [s]")
print(g_qq2)
```

La forma de los datos en el gráfico no se aleja tanto de una recta, y podemos ver que no hay evidencia de valores atípicos, pues no hay puntos fuera de la banda coloreada.

Como no hay indicios de que tengamos que ser cautelosos con los resultados, fijamos el nivel de significación en 0,05.

Ahora debemos formular las hipótesis:
H0
: tras el entrenamiento, la media de las mejores marcas de los atletas de raza oriental en los 100 metros planos se redujo en 6,45 segundos, es decir, si di=xantesi−xdespuési
, entonces μd=6,45
 [s], donde (xantesi,xdespuési)
 son los mejores registros antes y despúes del entrenamiento, respectivamente, observados para el i
-ésimo atleta.

HA
: tras el entrenamiento, la media de las mejores marcas de los atletas de raza oriental en los 100 metros planos se redujo en menos de 6,45 segundos, es decir μd<6,45
 [s]).

Debemos fijarnos bien en qué orden vamos a calcular las diferencias. Como escribimos las hipótesis, si se resta la media de los mejores tiempos después del entrenamiento a la media de los mejores tiempos antes del entrenamiento, esperamos que esta diferencia sea positiva (mayores tiempos antes del entrenamiento), por lo que el valor nulo también debe ser positivo y la hipótesis alternativa es que la verdadera diferencia promedio es menor (less) a este valor. Si hubiéramos considerado la diferencia como la media de los mejores tiempos después del entrenamiento menos la media de los mejores tiempos antes del entrenamiento, esperaríamos un valor negativo y, en consecuencia, el valor nulo ha de ser negativo y la hipótesis alternativa esperaría encontrar un valor mayor (greater) a este número hipotético. Efectuamos (solo por esta vez, por razones pedagógicas) ambas versiones de la prueba con estas consideraciones:

```{r}
alfa_2 <- 0.05
valor_nulo_2a <- 6.45
valor_nulo_2b <- -6.45

prueba_2a <- t.test(x = datos_2_ant, y = datos_2_pos,
                    alternative = "less", mu = valor_nulo_2a,
                    paired = TRUE, conf.level = 1 - alfa_2)
prueba_2b <- t.test(x = datos_2_pos, y = datos_2_ant,
                    alternative = "greater", mu = valor_nulo_2b,
                    paired = TRUE, conf.level = 1 - alfa_2)

cat("Prueba de hipótesis pregunta 2:\n")
print(prueba_2a)
print(prueba_2b)
```

Ahora podemos concluir.
El análisis indica que debemos rechazar hipótesis nula en favor de la alternativa (t(26)=23,058;p<0,001
), por lo que podemos concluir, con 95% de confianza, que la mejor marca de los atletas de raza oriental en los 100 metros planos se redujo en promedio menos de 6,45 segundos (95% CI para la media de las diferencias: [−∞;5,076]
 [s]) tras el entrenamiento.
 
### Pregunta 3 : ¿Es posible afirmar que, en promedio, los atletas de raza negra superan a los de raza blanca por más de 2 segundos después del entrenamiento?

En este caso, debemos inferir acerca de las medias de dos muestras independientes, es decir sobre la diferencia de las medias de las poblaciones de donde provienen las muestras. Obtengamos las muestras con las que trabajaremos y sus tamaños

```{r}
datos_3_neg <- datos |> filter(Raza == "Negra") |> pull(Posterior)
datos_3_bla <- datos |> filter(Raza == "Blanca") |> pull(Posterior)
n_3_neg <- length(datos_3_neg)
n_3_bla <- length(datos_3_bla)

cat("Tamaño de las muestras:", n_3_neg, "y", n_3_bla, "\n")
```
Como las muestras son pequeñas (menos de 30 observaciones) y no conocemos la(s) desviación(es) estándar(es) de la(s) población(es), sería adecuado usar la prueba t de Student para dos muestras independientes. Pero antes debemos verificar las condiciones. Como en el caso de ambas muestras se trata de 28 y 26 atletas diferentes, menor al 10% de la población respectiva, y la elección de una/o en particular no influye en ñla elección de otra/o, podemos suponer que las observaciones son independientes entre sí. Ahora debemos verificar si cada una de las muestras presenta una distribución cercana a la normal.

```{r}
norm_3_neg <- shapiro.test(datos_3_neg)
norm_3_bla <- shapiro.test(datos_3_bla)

cat("Comprobación de la normalidad de los datos:\n")
cat("------------------------------------------:\n")
cat("Primera muestra:\n")
print(norm_3_neg)
cat("Segunda muestra:\n")
print(norm_3_bla)
```

Podemos ver que, en ambos casos, las pruebas de normalidad resultan negativas (raza negra: W=0,952;p=0,223
; raza blanca: W=0,947;p=0,201
), por lo que es razonable suponer que ambas muestras provienen de una o dos distribuciones cercanas a la distribuciónnormal.

Como no hay indicios de que tengamos que ser cautelosos con los resultados, fijamos el nivel de significación en 0,05.

Ahora debemos formular las hipótesis:

H0
: después del entrenamiento, en promedio, los atletas de raza negra superan a los de raza blanca por 2 segundos, es decir |μdespuésN−μdespuésB|=2
 [s], donde μdespuésN
 y μdespuésB
 son las medias de los mejores registros despúes del entrenamiento de los atletas de raza negra y de raza blanca, respectivamente.

HA
: tras del entrenamiento, en promedio, los atletas de raza negra superan a los de raza blanca por más de 2 segundos, es decir |μdespuésN−μdespuésB|<2
 [s]).

Realicemos la prueba con estas consideraciones y tendiendo cuidado de ser consistentes con si obtendremos una diferencia positiva o negativa y ejecutar la versión adecuada para muestras independientes (es decir, la prueba de Welch).

```{r}
alfa_3 <- 0.05
valor_nulo_3 <- 2

prueba_3 <- t.test(x = datos_3_bla, y = datos_3_neg, alternative = "greater",
                   mu = valor_nulo_3, paired = FALSE, conf.level = 1 - alfa_3)

cat("Prueba de hipótesis pregunta 3:\n")
print(prueba_3)
```

Interpretemos estos resultados.
No hay evidencia suficiente para rechazar hipótesis nula (t(50,8)=3,838;p>0,999
), por lo que podemos concluir, con 95% de confianza, que en promedio las mejores marcas de los atletas de raza negra no supera a las de los atletas de raza blanca en más de 2 segundos (95% CI para la diferencia de las medias: [0,305;∞]
 [s]) tras el entrenamiento.
 
### Pregunta 4 : ¿Será cierto que hay más atletas de raza blanca que redujeron sus mejores marcas en menos de 2,8 segundos que atletas de raza negra que lo hicieron en menos de 1,5 segundos?

Primero debemos notar que aquí no nos preguntan por un valor de la variable medida (mejor tiempo registrado por cada atleta), sino que del número de atletas que cumple una característica (frecuencias). En particular, nos piden inferir sobre la diferencia entre dos proporciones a partir de dos muestras independientes de la población.

Formulemos las hipótesis:

H0
: la proporción de atletas de raza blanca que redujeron sus mejores marcas en menos de 2,8 segundos (pD<2,8B
) no es distinta a la proporción de atletas de raza negra que redujeron sus mejores marcas en menos de 1,5 segundos (pD<1,5N
). Matemáticamente: p~D<2,8B−p~D<1,5N=0
.

HA
: la proporción de atletas de raza blanca que redujeron sus mejores marcas en menos de 2,8 segundos es mayor a la proporción de atletas de raza negra que redujeron sus mejores marcas en menos de 1,5 segundos. Matemáticamente: pD<2,8B−pD<1,5N>0
.

Obtengamos los datos que necesitamos trabajar. Primero filtramos para dejar los atletas de interés, luego creamos una columna con la disminución de tiempo logrado por el programa de entrenamiento y, finalmente, contamos los éxitos y los totales según lo indicado en el enunciado.

```{r}
datos_4 <- datos |> filter(Raza == "Blanca" | Raza ==  "Negra")  |>
  mutate(disminucion = abs(Posterior - Previo))

n_4_bla <- datos_4 |> filter(Raza == "Blanca") |> nrow()
e_4_bla <- datos_4 |> filter(Raza == "Blanca") |> filter(disminucion >= 2.9) |> nrow()

n_4_neg <- datos_4 |> filter(Raza == "Negra") |> nrow()
e_4_neg <- datos_4 |> filter(Raza == "Negra") |> filter(disminucion >= 1.6) |> nrow()
```

Corresponde revisar las condiciones para aplicar una prueba de la diferencia de dos proporciones de forma válida. Por un lado, las muestras son independientes pues, de acuerdo al enunciado, los atletas se eligieron de forma aleatoria y su tamaño es muy inferior al universo de atletas en el mundo. Faltaría entonces verificar que cada proporción, por separado, sigue el modelo normal.

```{r}
cat("Condiciones:\n")
cat("Éxitos y fracasos en la muestra de raza blanca:",
    e_4_bla, ",", n_4_bla - e_4_bla, "\n")
cat("Éxitos y fracasos en la muestra de raza negra:",
    e_4_neg, ",", n_4_neg - e_4_neg, "\n")
```

Vemos que las frecuencias encontradas cumplen (justito) la condición de éxito-fracaso (se espera observar al menos 10 éxitos y al menos 10 fracasos). Podemos entonces continuar con la prueba de proporciones.

Nota: Si la condición de éxito-fracaso no se cumpliera, se podrían seguir dos caminos. Primero, asegurarse de usar la corrección de continuidad de Yates al ejecutar la prueba (correct = TRUE) y considerar usar un nivel de significación exigente (α<0,05
). La segunda alternativa sería explorar métodos exactos que han estado saliendo en los últimos años, aunque estos no están tan validados por la comunidad todavía. Se puede consultar, por ejemplo:
Laurencelle, L. (2021). The exact binomial test between two independent proportions: A companion. The Quantitative Methods for Psychology, 17, 76-79.

Corresponde ahora realizar la prueba.

```{r}
prueba_4 <- prop.test(c(e_4_bla, e_4_neg), c(n_4_bla, n_4_neg), alternative = "greater")

cat("Pruebas de hipótesis pregunta 4:\n")
print(prueba_4)
```

Interpretemos estos resultados.
La prueba nos dice que no hay evidencia suficiente para rechazar la hipótesis nula (χ2(1)=0,335;p=0,281
). Así, no hay razones descartar que, tras el entrenamiento, la proporción de atletas de raza blanca que redujeron sus mejores marcas en menos de 2,8 [s] es igual a la proporción de atletas de raza negra que lo hicieron en menos de 1,5 [s] (95% CI para la diferencia de las proporciones: [−0,143;1,000]
 [s]).
 
# Lectura 4: Poder estadístico

## Enunciado

En una planta química hay dos máquinas que envasan detergentes industriales en bidones con un volumen de producto que sigue una distribución normal con desviación estándar de 1 litro. La ingeniera a cargo de la planta debe asegurar que los bidones se están llenando con una media de 10 litros. Pero ella tiene la sospecha de que hay desviaciones en esta media, lo que piensa confirmar usando una muestra aleatoria de 100 envases (50 de cada una de las máquinas). También cree que hay diferencia en el cumplimiento del volumen requerido entre la máquina más antigua y la más moderna, que han de andar por el 90% y 96% de los bidones, respectivamente.

### Pregunta 1 — prueba bilateral

#### Si la ingeniera piensa rechazar la hipótesis nula cuando la muestra presente una media menor a 9,9 litros o mayor a 10,1 litros, ¿cuál es la probabilidad de que cometa un error de tipo I?

Definimos los valores conocidos.

```{r}
desviacion.estandar <- 1
tamano.muestra <- 100
valor.nulo <- 10
cota.inferior <- 9.9
cota.superior <- 10.1
```

Del enunciado se desprende que se trata de una prueba t de Student para una muestra, con hipótesis alternativa bilateral, para la que podríamos enunciar las siguientes hipótesis.

H0
: el volumen medio (μV
) de los bidones de detergente es de 10 litros (μV=10
 [L]).
HA
: el volumen medio de los bidones es distinto de 10 litros (μV≠10
 [L]).

La probabilidad de cometer un error tipo I corresponde al nivel de significación (α
), que es lo que se solicita. El nivel de significación está dado por el área de la región de rechazo de la distribución que deberían seguir las medias muestrales bajo la hipótesis nula. En estos casos, esta distribución usualmente sigue una distribución t, pero en este enunciado en particular también se puede usar la distribución normal dado que se conoce la desviación estándar en la población y podemos calcular de forma exacta el error estándar.

```{r}
error.estandar <- desviacion.estandar / sqrt(tamano.muestra)

# Generemos una distribución normal en torno al valor nulo, con 5.000 valores.

puntos <- 5000

x <- seq(valor.nulo - 5.2 * error.estandar, valor.nulo + 5.2 * error.estandar,
         length.out = puntos)

y <- dnorm(x, mean = valor.nulo, sd = error.estandar)
distr <- data.frame(x, y)

# Con esta simulación, graficamos la distribución muestral.

# Definimos una paleta de colores.
colores <- hcl(h = (seq(15, 255, length.out = 3)), c = 100, l = 65)

# Comenzamos por la cuadrícula con fondo blanco.
g.dist <- ggplot(data = distr, aes(x))
g.dist <- g.dist + theme_pubr()

# Agregamos la distribución normal.
g.dist <- g.dist +
          stat_function(fun = dnorm,
                        args = list(mean = valor.nulo, sd = error.estandar),
                        colour = colores[1], linewidth = 1)

# Quitamos las etiquetas y marcas del eje y.
g.dist <- g.dist + ylab("")
g.dist <- g.dist + scale_y_continuous(breaks = NULL)

# Agregamos marcas y etiquetas rotadas al eje x.
g.dist <- g.dist +
          scale_x_continuous(name = "Volumen [L]",
                             breaks = seq(round(min(x), 1), round(max(x), 1), 0.1))
g.dist <- g.dist +
          theme(axis.text.x = element_text(angle = 30, size = 10))

# Agregamos la media bajo la hipótesis nula.
g.dist <- g.dist +
          geom_vline(xintercept = valor.nulo,
                     colour = colores[1], linetype = "longdash")

# Agregamos el título.
g.dist <- g.dist + ggtitle("Distribución de las medias muestrales bajo H0")

# Finalmente Mostramos el gráfico.
print(g.dist)
```

Ahora podemos marcar las regiones de rechazo definidas por el ingeniero.

```{r}
# Marcamos el lado izquierdo.
g.1.bilateral <- g.dist +
                 geom_area(data = subset(distr, x < cota.inferior),
                           aes(y = y), colour = colores[1],
                           fill = colores[1], alpha = 0.5)

# Marcamos el lado derecho.
g.1.bilateral <- g.1.bilateral +
                 geom_area(data = subset(distr, x > cota.superior),
                           aes(y = y), colour = colores[1],
                           fill = colores[1], alpha = 0.5)

# Agregamos el título y mostramos el gráfico
g.1.bilateral <- g.1.bilateral + ggtitle("Pregunta 1 - hipótesis bilateral")
print(g.1.bilateral)
```

Se puede apreciar que la ingeniera definió grandes regiones de rechazo. Esperamos entonces un nivel de significación alto. Calculemos esta probabilidad (como el área de estas regiones).

```{r}
alfa_izquierdo <- pnorm(cota.inferior, mean = valor.nulo, sd = error.estandar,
                        lower.tail = TRUE)
alfa_derecho <- pnorm(cota.superior, mean = valor.nulo, sd = error.estandar,
                      lower.tail = FALSE)
alfa.1.bilateral <- alfa_izquierdo + alfa_derecho

# Y mostremos el resultado en pantalla.

cat("La probabilidad de cometer un error tipo I es alfa =", alfa.1.bilateral,"\n\n")
```

Interpretemos este análisis.
Con los umbrales definidos por la ingeniera para rechazar la hipótesis nula (9,9 y 10,1 litros), la probabilidad de que cometa un error de tipo I es α=0,317.

### Pregunta 2 — prueba bilateral
Si el verdadero volumen medio de los bidones fuera de 9,95 litros, ¿cuál sería la probabilidad de que la ingeniera, que obviamente no conoce este dato, cometa un error de tipo II?

Es importante darse cuenta de que estamos trabajando con la misma prueba, solo que ahora conocemos la verdadera media (lo que no ocurre en la realidad). Para responder, construimos un gráfico de la distribución muestral con esta verdadera media que superponemos al de la hipótesis nula. Primero simulamos 5.000 valores.

```{r}
media.bilateral <- 9.95

x1 <- seq(media.bilateral - 5.2 * error.estandar,
          media.bilateral + 5.2 * error.estandar, length.out = puntos)

y1 <- dnorm(x1, mean = media.bilateral, sd = error.estandar)
distr1 <- data.frame(x = x1, y = y1)
Y graficamos la curva de esta verdadera distribución muestral.

g.2.bilateral <- g.1.bilateral +
                 stat_function(fun = dnorm, n = puntos,
                               args = list(mean = media.bilateral, sd = error.estandar),
                               colour = colores[3], linewidth = 1)

g.2.bilateral <- g.2.bilateral +
                 geom_vline(xintercept = media.bilateral, colour = colores[3],
                            linetype = "longdash")

g.2.bilateral <- g.2.bilateral + ggtitle("Pregunta 2 - hipótesis bilateral")
print(g.2.bilateral)
```

El error tipo II significa no rechazar la hipótesis nula cuando esta es falsa. En este caso, no rechazar la idea de que la media de la población es 10 [L], siendo que en realidad es 9,95 [L]. Este tipo de error ocurre si la media muestral cae fuera de las regiones críticas definidas por la ingeniera. Marquemos esta región.

```{r}
g.2.bilateral <- g.2.bilateral + geom_area(
  data = subset(distr1, x >= cota.inferior & x <= cota.superior),
  aes(y = y), colour = colores[3], fill = colores[3], alpha = 0.5)
print(g.2.bilateral)
```

Es decir, se comete un error de tipo II cuando la media de la muestra sea mayor al umbral inferior y menor al umbral superior escogidas por la ingeniera. Calculemos esta probabilidad (área de la región azul).

```{r}
# Calcular la probabilidad de esta región (beta)
beta.superior <- pnorm(cota.superior, mean = media.bilateral,
                       sd = error.estandar, lower.tail = TRUE)

beta.inferior <- pnorm(cota.inferior, mean = media.bilateral,
                       sd = error.estandar, lower.tail = TRUE)

beta.bilateral <- beta.superior - beta.inferior
```
Y mostremos el resultado en pantalla.

```{r}
cat("La probabilidad de cometer un error tipo II es beta =", beta.bilateral, "\n\n")
La probabilidad de cometer un error tipo II es beta = 0.6246553 

```
Ahora podemos responder.

Si la verdadera media fuera 9,95 [L], con los umbrales definidos por la ingeniera para rechazar la hipótesis nula (9,9 y 10,1 litros), la probabilidad de que cometa un error de tipo II sería β
=0,625.

### Pregunta 3 — prueba bilateral
Como no se conoce el verdadero volumen medio, genere un gráfico del poder estadístico con las condiciones anteriores, pero suponiendo que el verdadero volumen medio podría variar de 9,6 a 10,4 litros.

Como es extremadamente inusual conocer la verdadera media de la población, es más realista revisar cómo cambia la probabilidad de detectar que H0
 es falsa para diferentes valores de la verdadera media. Esta probabilidad es lo que se conoce como el poder estadístico (o potencia estadística) y lo que se nos pide es un gráfico de cómo cambia a medida que se acerca o aleja del valor nulo considerado.

Para mayor facilidad, primero definimos una función que calcule el poder estadísticos para una media, un error estándar y umbrales dados.

```{r}
calcula_poder <- function(media, error_estandar, umbral_inf = NULL, umbral_sup = NULL) {
  poder_inf <- 0
  poder_sup <- 1
  
  if(!is.null(umbral_inf))
    poder_inf <- pnorm(umbral_inf, mean = media, sd = error_estandar,
                       lower.tail = TRUE)
  if(!is.null(umbral_sup))
    poder_sup <- pnorm(umbral_sup, mean = media, sd = error_estandar,
                       lower.tail = FALSE)
  
  poder <- poder_inf + poder_sup
  return(poder)
}
```
Nota:
Esta función maneja hipótesis alternativas tanto bilaterales como unilaterales. Basta dar valor NULL al umbral no definido.

Generamos algunos puntos en el rango indicado en la pregunta para poder graficar, considerando el error estándar y umbrales definidos en el enunciado.

```{r}
x3 <- seq(9.6, 10.4, 0.01)
y3 <- sapply(x3, calcula_poder, error_estandar = error.estandar,
             umbral_inf = cota.inferior, umbral_sup = cota.superior)
distr3 <- data.frame(x = x3, y = y3)
Ahora generamos el gráfico con la curva de poder.

g.3.bilateral <- ggplot(distr3, aes(x, y)) + ylim(c(0, 1))
g.3.bilateral <- g.3.bilateral + 
                 scale_x_continuous(name = "Volumen media verdadero [L]",
                                    breaks = seq(round(min(x3), 1), round(max(x3), 1), 0.1))
g.3.bilateral <- g.3.bilateral + geom_line(colour = colores[2])
g.3.bilateral <- g.3.bilateral + ylab("Poder estadístico")
g.3.bilateral <- g.3.bilateral + theme_pubr()
g.3.bilateral <- g.3.bilateral + 
                 theme(axis.text.x = element_text(angle = 30, size = 10))
g.3.bilateral <- g.3.bilateral + ggtitle("Pregunta 3 - hipótesis bilateral")

print(g.3.bilateral)
```

En el gráfico se puede ver la curva de poder que resulta, la cual se acerca a uno a medida que la verdadera media se aleja del valor de la hipótesis nula (10 [L]), mientras que disminuye a medida que se acerca a este valor, donde alcanza su valor mínimo que corresponde a la probabilidad de rechazar H0
 cuando, después de todo, es verdadera. Es decir, este valor es la probabilidad de cometer un error de tipo I (α
).

### Pregunta 4 — prueba bilateral
Considerando la suposición de que el verdadero volumen medio de los bidones es de 9,95 litros, ¿cuántos bidones deberían revisarse para conseguir un poder estadístico de 0,9 y un nivel de significación de 0,05?

Aquí se pregunta por el tamaño de la muestra para conseguir los valores para los factores de la prueba dados tanto explícitamente (α
= 0,05 y (1−β)
=0,90) como implícitamente, que en este caso es el tamaño del efecto: δ=|μV−μ0|=
 |
 9,95 −
 10,00 |
 =
 0,05.

Recordemos que el paquete pwr contiene funciones para responder este tipo de preguntas, pero que utilizan el tamaño del efecto expresado como la d
 de Cohen. En este caso:

efecto.bilateral <- (media.bilateral - valor.nulo) / desviacion.estandar
Si consideramos que estamos realizando una prueba Z, se puede usar la función para este tipo.

```{r}
library(pwr)

poder.z.bilateral <- pwr.norm.test(d = efecto.bilateral, sig.level = 0.05,
                                   power = 0.90, alternative = "two.sided")
print(poder.z.bilateral)

     Mean power calculation for normal distribution with known variance 

              d = 0.05
              n = 4202.968
      sig.level = 0.05
          power = 0.9
    alternative = two.sided
tamano.z.bilateral <- ceiling(poder.z.bilateral[["n"]])
cat("El tamaño de la muestra para una prueba Z debe ser n =",
    tamano.z.bilateral, "\n\n")
El tamaño de la muestra para una prueba Z debe ser n = 4203 
Si en vez consideramos una prueba t de Student, usamos la función para esa prueba.

poder.t1.bilateral <- pwr.t.test(d = efecto.bilateral, sig.level = 0.05,
                                 power = 0.90, type = "one.sample",
                                 alternative = "two.sided")
print(poder.t1.bilateral)
```
     One-sample t test power calculation 

              n = 4204.889
              d = 0.05
      sig.level = 0.05
          power = 0.9
    alternative = two.sided
    
```{r}
tamano.t1.bilateral <- ceiling(poder.t1.bilateral[["n"]])
cat("El tamaño de la muestra para una prueba t debe ser n =",
    tamano.t1.bilateral, "\n\n")
El tamaño de la muestra para una prueba t debe ser n = 4205 
Otra alternativa es usar la función power.t.test() (disponible en el core de R) que considera el tamaño del efecto expresado en la escala de la variable (δ
).

diferencia.bilateral <- media.bilateral - valor.nulo
poder.t2.bilateral <- power.t.test(delta = diferencia.bilateral,
                                   sd = desviacion.estandar,
                                   sig.level = 0.05, power = 0.90,
                                   type = "one.sample",
                                   alternative = "two.sided")
print(poder.t2.bilateral)
```
     One-sample t test power calculation 

              n = 4204.89
          delta = 0.05
             sd = 1
      sig.level = 0.05
          power = 0.9
    alternative = two.sided
```{r}
tamano.t2.bilateral <- ceiling(poder.t2.bilateral[["n"]])
cat("El tamaño de la muestra para una prueba t debe ser n =",
    tamano.t2.bilateral, "\n\n")
```


El tamaño de la muestra para una prueba t debe ser n = 4205 
Podemos ver que las alternativas para la prueba t de Student llevan al mismo resultado, mientras que usando una prueba Z se llega a un número muy similar. Escribamos la conclusión considerando esta última prueba.

Suponiendo que el verdadero volumen medio de los bidones es de 9,95, se necesita una muestra de al menos 4.203 bidones para conseguir un poder estadístico de 0,9 y un nivel de significación de 0,05. Lo lógico, si ambas máquinas se usan con igual productividad, sería obtener muestras de 2.102 bidones de la máquina antigua e igual número de bidones de la máquina más moderna.

### Pregunta 5 — prueba bilateral
¿Alcanzaría esta muestra para detectar la diferencia que la ingeniera sospecha que existe entre las dos máquinas de la planta con las mismas probabilidades de cometer errores?

Primero debemos notar que esta pregunta considera que la ingeniera sospecha que existe una diferencia en la tasa de cumplimiento del volumen requerido entre las dos máquinas de la planta. Es decir, ahora vamos a considerar las siguientes hipótesis.

H0
: la tasa de bidones que cumplen el volumen requerido de 10 [L] que obtiene la máquina antigua (pantigua
) es la misma que consigue la máquina moderna (pmoderna
); es decir pantigua−pantigua=0
.
HA
: las tasas de bidones que cumplen el volumen requerido que obtienen las máquinas de la planta son distintas; es decir pantigua−pantigua≠0
.

Aquí se pregunta por el tamaño de la muestra para mantener las probabilidades de cometer errores de la pregunta anterior (α
= 0,05 y (1−β)
=0,90), pero ahora para contrastar estas nuevas hipótesis.

Para responder la duda de la ingeniera podemos seguir diferentes caminos:

usando el tamaño del efecto sospechado por la ingeniera, el tamaño de la muestra calculado en la pregunta anterior y fijando el nivel de significación, obtener la potencia de la prueba y verificar si es igual o mayor al 90% solicitado;
análogo a lo anterior, pero fijando la potencia y calculando el nivel de significación conseguido para comprobar si cumple el 5% solicitado; o
fijar los factores de la prueba y calcular el tamaño de la muestra necesitado, para compararlo con el tamaño requerido para la pregunta anterior.
Aquí seguiremos la tercera estrategia.

```{r}
# Obtenemos el tamaño del efecto
p.antigua <- 0.90
p.moderna <- 0.96
p.h <- ES.h(p.antigua, p.moderna)

# Obtenemos los tamaños de las muestras
poder.2p <- pwr.2p.test(h = p.h, sig.level = 0.05, power = 0.90, alternative = "two.sided")
print(poder.2p)
```
     Difference of proportion power calculation for binomial distribution (arcsine transformation) 

              h = 0.2407853
              n = 362.4651
      sig.level = 0.05
          power = 0.9
    alternative = two.sided

NOTE: same sample sizes
```{r}
tamano.2p <- ceiling(poder.2p[["n"]])
mje <- paste0("El tamaño de las muestras para una prueba de la diferencia\n",
              "de dos proporciones independientes n =")
cat(mje, tamano.2p, "\n\n")
```
El tamaño de las muestras para una prueba de la diferencia
de dos proporciones independientes n = 363 
Podemos concluir fácilmente:

Para resolver la duda sobre la igualdad o diferencia de las tasas de cumplimiento del llenado de bidones por las dos máquinas de la planta, se necesitarían muestras de 363 bidones de cada una para conseguir un poder estadístico de 90% y un nivel de significación del 5% considerando una diferencia hipotética de 6%.

De este modo, las muestras de 2.102 bidones de cada máquina requerida para responder la pregunta anterior serían más que suficientes en este caso.

### Pregunta 1 — prueba unilateral
Si la ingeniera está segura de que el verdadero volumen medio no puede ser inferior a 10 litros y piensa rechazar la hipótesis nula cuando la muestra presente una media mayor a 10,1 litros, ¿cuál es la probabilidad de que cometa un error de tipo I?

Definimos los valores conocidos.

```{r}
desviacion.estandar <- 1
tamano.muestra <- 100
valor.nulo <- 10
cota.inferior <- NULL
cota.superior <- 10.1
```
Ahora trabajamos con una prueba t de Student para una muestra con hipótesis alternativa unilateral, para la que se puede enunciar las siguientes hipótesis.

H0
: el volumen medio (μV
) de los bidones de detergente es de 10 litros (μV=10
 [L]).
HA
: el volumen medio de los bidones es mayor a 10 litros (μV>10
 [L]).

Como vimos en el caso de una prueba bilateral, nos preguntan por la probabilidad de cometer un error tipo I que corresponde al nivel de significación α
, el cual está dado por el área de la región de rechazo de la distribución que deberían seguir las medias muestrales bajo la hipótesis nula. Como conocemos la desviación estándar de la población, usemos una vez más la distribución normal (prueba Z).

Tomando como base el gráfico de la distribución normal que hicimos para el caso bilateral, ahora marcamos la única región de rechazo definida por la ingeniera.
```{r}
g.1.unilateral <- g.dist + 
                  geom_area(data = subset(distr, x > cota.superior),
                            aes(y = y), colour = colores[1],
                            fill = colores[1], alpha = 0.5)

g.1.unilateral <- g.1.unilateral +
                  ggtitle("Pregunta 1 - hipótesis unilateral")

print(g.1.unilateral)
```

Calculemos la probabilidad asociada a esta región de rechazo que corresponde a su área.

```{r}
# Calcular la probabilidad de la región de rechazo.
alfa.1.unilateral <- pnorm(cota.superior, mean = valor.nulo,
                           sd = error.estandar, lower.tail = FALSE)

cat("La probabilidad de cometer un error tipo I es alfa =", alfa.1.unilateral, "\n\n")
```
La probabilidad de cometer un error tipo I es alfa = 0.1586553 
Interpretemos lo obtenido.

Considerando la que la ingeniera va a rechazar la hipótesis nula cuando la muestra presente una media mayor a 10,1 litros, la probabilidad de que cometa un error de tipo I es α=
 0,159.

### Pregunta 2 — prueba unilateral
Si el verdadero volumen medio de los bidones fuera de 10,05 litros, ¿cuál sería la probabilidad de que la ingeniera, que obviamente no conoce este dato, cometa un error de tipo II?

Para responder, superponemos al gráfico anterior (hipótesis nula) la curva de la distribución muestral con esta verdadera media. Simulamos valores y graficamos la curva.

```{r}
media.unilateral <- 10.05
x2 <- seq(media.unilateral - 5.2 * error.estandar,
          media.unilateral + 5.2 * error.estandar, length.out = puntos)

y2 <- dnorm(x2, mean = media.unilateral, sd = error.estandar)
distr2 <- data.frame(x = x2, y = y2)

g.2.unilateral <- g.1.unilateral + 
                  stat_function(fun = dnorm, n = puntos,
                                args = list(mean = media.unilateral, sd = error.estandar),
                                colour = colores[3], linewidth = 1)

g.2.unilateral <- g.2.unilateral +
                  geom_vline(xintercept = media.unilateral,
                             colour = colores[3],
                             linetype = "longdash")
Recordando que el error tipo II significa no rechazar la hipótesis nula cuando esta es falsa, lo que en este caso se traduce no rechazar la idea de que la media de la población es 10 [L], siendo que en realidad es 10,05 [L]. Marquemos la región que incluya las medias muestrales que caen fuera de la región crítica definida por el ingeniero.

g.2.unilateral <- g.2.unilateral +
                  geom_area(data = subset(distr2, x <= cota.superior),
                            aes(y = y), colour = colores[3],
                            fill = colores[3], alpha = 0.5)

g.2.unilateral <- g.2.unilateral + ggtitle("Pregunta 2 - hipótesis unilateral")
print(g.2.unilateral)
```

Calculemos esta probabilidad.

```{r}
# Calcular la probabilidad de esta región (beta)
beta.unilateral <- pnorm(cota.superior, mean = media.unilateral,
                         sd = error.estandar, lower.tail = TRUE)

cat("La probabilidad de cometer un error tipo II es beta =", beta.unilateral,
    "\n\n")
```
La probabilidad de cometer un error tipo II es beta = 0.6914625 
Respondemos la pregunta.
Con un valor para la verdadera media de 10.05 [L] y el umbral definido por la ingeniera para rechazar la hipótesis nula (10,1 litros), la probabilidad de cometer un error de tipo II sería β
=0,691.

### Pregunta 3 — prueba unilateral
Como no se conoce el verdadero volumen medio, genere un gráfico del poder estadístico con las condiciones anteriores, pero suponiendo que el verdadero volumen medio podría variar de 10 a 10,3 litros.

Tal como en el caso bilateral nos piden la curva del cambio de la probabilidad de detectar que H0
 es falsa (es decir, el poder estadístico) para diferentes valores de la verdadera media.

Usaremos la función ya presentada que calcula el poder.

Generamos algunos puntos en el rango indicado en la pregunta para poder graficar, considerando el error estándar y el umbral definido en el enunciado.
```{r}
x4 <- seq(9.75, 10.25, 0.01)
y4 <- sapply(x4, calcula_poder, error_estandar = error.estandar,
             umbral_inf = cota.inferior, umbral_sup = cota.superior)
distr4 <- data.frame(x = x4, y = y4)
Ahora generamos el gráfico con la curva de poder.

g.3.unilateral <- ggplot(distr4, aes(x, y)) + ylim(c(0, 1))
g.3.unilateral <- g.3.unilateral + geom_line(colour = colores[2])
g.3.unilateral <- g.3.unilateral + ylab("Poder estadístico")
g.3.unilateral <- g.3.unilateral + xlab("Volumen media verdadero [L]")
g.3.unilateral <- g.3.unilateral + theme_pubr()
g.3.unilateral <- g.3.unilateral +
                  theme(axis.text.x = element_text(angle = 30, size = 10))
g.3.unilateral <- g.3.unilateral + ggtitle("Pregunta 3 - hipótesis unilateral")

print(g.3.unilateral)
```

En el gráfico se puede ver la curva de poder que resulta, la que es muy cercana a cero cuando es menor que el valor nulo (puesto que esto fue considerado como imposible por la ingeniera), pasa por el valor de α
 cuando la verdadera media coincide con la hipótesis nula (10 [L]), para acercarse al valor uno mientras más se aleja a la derecha de este valor.

### Pregunta 4 — prueba unilateral
Considerando un volumen medio de 10 litros, ¿cuántos bidones deberían revisarse para conseguir un poder estadístico de 0,9 y un nivel de significación de 0,05?

Aquí tenemos las mismas alternativas que para la prueba bilateral considerando α
= 0,05, (1−β)
=0,90 y δ=|μV−μ0|=
 |10,50−10,00|=0,05
.

Calculemos el tamaño del efecto expresado como la d
 de Cohen. En este caso:
```{r}
diferencia.unilateral <- media.unilateral - valor.nulo
efecto.unilateral <- diferencia.unilateral / desviacion.estandar
Primero consideremos una prueba Z.

poder.z.unilateral <- pwr.norm.test(d = efecto.unilateral, sig.level = 0.05,
                                    power = .9, alternative = "greater")
print(poder.z.unilateral)
```
## 
##      Mean power calculation for normal distribution with known variance 
## 
##               d = 0.05
##               n = 3425.539
##       sig.level = 0.05
##           power = 0.9
##     alternative = greater
Consideramos una prueba t de Student usando el paquete pwr.
```{r}
poder.t1.unilateral <- pwr.t.test(d = efecto.unilateral, sig.level = 0.05,
                                 power = 0.9, type = "one.sample",
                                 alternative = "greater")
print(poder.t1.unilateral)
```
## 
##      One-sample t test power calculation 
## 
##               n = 3426.892
##               d = 0.05
##       sig.level = 0.05
##           power = 0.9
##     alternative = greater
Finalmente comprobamos la alternativa con el tamaño del efecto expresado en como δ
.
```{r}
poder.t2.unilateral <- power.t.test(delta = diferencia.unilateral,
                                    sd = desviacion.estandar,
                                    sig.level = 0.05, power = 0.9,
                                    type = "one.sample",
                                    alternative = "one.sided")
print(poder.t2.unilateral)
```
## 
##      One-sample t test power calculation 
## 
##               n = 3426.892
##           delta = 0.05
##              sd = 1
##       sig.level = 0.05
##           power = 0.9
##     alternative = one.sided
Confirmamos que las alternativas para la prueba t de Student llevan al mismo resultado, muy similar al que se llega usando una prueba Z, Escribamos la conclusión con esta última prueba.

Suponiendo que el verdadero volumen medio de los bidones es de 10,05, se necesita una muestra de al menos 3.426 bidones (1.713 de cada máquina) para conseguir una prueba Z con un poder estadístico de 0,9 y un nivel de significación de 0,05.

### Pregunta 5 — prueba unilateral
¿Alcanzaría esta muestra para detectar que la tasa de cumplimiento de la máquina más moderna es mejor que la alcanzada por la máquina más antigua?

Como para el caso bilateral, esta pregunta considera una posible diferencia en la tasa de cumplimiento del volumen requerido entre las dos máquinas de la planta, aunque esta vez solamente consideramos la posibilidad de que esta tasa es mayor en la máquina más moderna. Las hipótesis serían:

H0
: la tasa de bidones que cumplen el volumen requerido de 10 [L] que obtiene la máquina antigua (pantigua
) es la misma que consigue la máquina moderna (pmoderna
); es decir pantigua−pantigua=0
.
HA
: las tasas de bidones que cumplen el volumen requerido que obtienen la máquina antigua es menor que la obtenida por la máquina moderna; es decir pantigua−pantigua<0
.

Aquí también nos interesa conocer el tamaño de la muestra que permitiría mantener las probabilidades de cometer errores de la pregunta anterior (α
= 0,05 y (1−β)
=0,90), pero ahora para contrastar estas nuevas hipótesis.

Siguiendo la lógica usada en el caso bilateral, podemos ejecutar el siguiente código:
```{r}
# Obtenemos el tamaño del efecto
p.antigua <- 0.90
p.moderna <- 0.96
p.h <- ES.h(p.antigua, p.moderna)

# Obtenemos los tamaños de las muestras
poder.2p <- pwr.2p.test(h = p.h, sig.level = 0.05, power = 0.90, alternative =  "less")
print(poder.2p)
```
     Difference of proportion power calculation for binomial distribution (arcsine transformation) 

              h = -0.2407853
              n = 295.4195
      sig.level = 0.05
          power = 0.9
    alternative = less

NOTE: same sample sizes
```{r}
tamano.2p <- ceiling(poder.2p[["n"]])
mje <- paste0("El tamaño de las muestras para una prueba unilateral de la\n",
              "diferencia de dos proporciones independientes es n =")
cat(mje, tamano.2p, "\n\n")
```
El tamaño de las muestras para una prueba unilateral de la
diferencia de dos proporciones independientes es n = 296 
Notemos que la única diferencia con el código usado en el caso bilateral es que indicamos que la hipótesis alternativa solamente considera la cola inferior (alternative = less). Interpretemos el resultado.

Para contrastar las hipótesis sobre las tasas de cumplimiento del llenado de bidones por parte de las dos máquinas de la planta, se necesitarían muestras de 296 bidones de cada una para conseguir un poder estadístico de 90% y un nivel de significación del 5% considerando una diferencia hipotética de 6%.

De este modo, las muestras de 1.713 bidones de cada máquina requerida para responder la pregunta anterior serían más que suficientes para esta prueba.

# Lectura 5: Pruebas no paramétricas

### Pregunta 1: Prueba Chi-chuadrado de homogeneidad
#### Una organización de conservación de la fauna silvestre estudia manadas de tres tipos de animales herbívoros en reservas naturales africanas. Se seleccionó aleatoriamente una muestra de 30 observaciones de los animales que se acercaron a beber agua en el principal afluente de las reservas Etosha y Mahago durante tres días consecutivos del mes de febrero. Se registraron 7 elefantes, 8 antílopes y 15 cebras en la primera, y 7 elefantes, 14 antílopes y 9 cebras en la segunda. ¿Existe evidencia de que la proporción de especies es la misma en ambas reservas?

En este caso tenemos una tabla de contingencia de dos vías y se busca determinar si los diferentes niveles de la variable categórica (las reservas) tienen las mismas proporciones de tres tipos de animales, por lo que una buena opción es usar una prueba χ2
 de homogeneidad.

Las hipótesis a contrastar serían:
H0
: Las reservas tienen iguales proporciones de los animales estudiados.

Ha
: Las reservas tienen proporciones diferentes de los animales estudiados.

En esta ocasión “reconstruir” los datos parece necesitar mucho esfuerzo. Por esto, es mejor definir la tabla de frecuencias observadas directamente.

```{r}
library(dplyr)

Etosha <- c(7, 8, 15)
Mahago  <- c(7, 14, 9)

tabla1_obs <- rbind(Etosha, Mahago)
colnames(tabla1_obs) <- c("Elefantes", "Antílopes", "Cebras")

Total1_obs <- Etosha + Mahago
tabla1_obs_total <- rbind(tabla1_obs, Total = Total1_obs)
tabla1_obs_total |>
  kable(booktabs = TRUE, caption = "Frecuencias observadas") |>
  kable_styling(full_width = FALSE) |>
  kable_styling(bootstrap_options = c("striped")) |>
  row_spec(3, bold = TRUE) |>
  add_header_above(c("Reserva", "Animal" = 3))
```
Frecuencias observadas
Reserva
Animal
Elefantes	Antílopes	Cebras
Etosha	7	8	15
Mahago	7	14	9
Total	14	22	24

Verifiquemos las condiciones para asegurar que podemos aplicar esta prueba con validez. Puesto que en cada categoría son animales diferentes, la muestra representa menos del 10% de la población de estos animales que viven en las reservas estudiadas (que deben ir de miles a cientos de miles), y la elección de un espécimen no debería influir en la elección de otro, para la misma especie ni para otra, podemos asumir que las observaciones son independientes entre sí.

Ahora debemos comprobar cuántas observaciones se esperan en cada grupo.

```{r}
margen_fila <- apply(tabla1_obs, 1, sum)
margen_columna <- apply(tabla1_obs, 2, sum)
n1 <- sum(tabla1_obs)
tabla1_esp <- margen_fila %*% t(margen_columna) / n1
rownames(tabla1_esp) <- c("Etosha", "Mahago")

Total1_esp <- margen_columna
tabla1_esp_total <- rbind(tabla1_esp, Total = Total1_esp)
tabla1_esp_total |>
  kable(booktabs = TRUE, caption = "Frecuencias esperadas") |>
  kable_styling(full_width = FALSE) |>
  kable_styling(bootstrap_options = c("striped")) |>
  row_spec(3, bold = TRUE) |>
  add_header_above(c("Reserva", "Animal" = 3))
```
Frecuencias esperadas
Reserva
Animal
Elefantes	Antílopes	Cebras
Etosha	7	11	12
Mahago	7	11	12
Total	14	22	24

Puesto que en cada caso se esperan más de 5 observaciones, podemos proceder sin problemas con la prueba seleccionada.

Consideremos un nivel de significación de 0,05 y realicemos la prueba.
```{r}
alfa1 <- 0.05
prueba1 <- chisq.test(x = tabla1_obs)

cat("Resultado de la prueba chi-cuadrado de homogeneidad:\n")
print(prueba1)
```
Resultado de la prueba chi-cuadrado de homogeneidad:

    Pearson's Chi-squared test

data:  tabla1_obs
X-squared = 3.1364, df = 2, p-value = 0.2084

En este punto, podemos responder la pregunta del enunciado.
El resultado de la prueba no permite rechazar la hipótesis nula en favor de la hipótesis alternativa (χ2=3,14;p=0,208
). Concluimos entonces, con 95% de confianza, que no hay suficiente evidencia para poder descartar que las reservas estudiadas tiene las mismas proporciones de elefantes, antílopes y cebras.

### Pregunta 2: Prueba exacta de Fisher
#### En otro planeta se realiza un estudio sobre la preferencia de hábitat de dos especies de alienígenas. Después de observar a una muestra de 17 alienígenas de la especie EA14012-A y 10 de la especie EA14013-B durante meses, se ha determinado que 5 alienígenas de la primera y 7 de la segunda prefieren hábitats subterráneos, mientras los demás prefieren hábitats acuáticos. ¿Existe relación entre las especies alienígenas y elegir hábitats subterráneos o hábitats acuáticos?

Primero vamos a “recrear” estos datos (por supuesto uno podría no hacer esta vuelta y crear la matriz de contingencia directamente).

```{r}
Habitat <- c(rep("Subterráneo", 5), rep("Acuático", 12), rep("Subterráneo", 9), rep("Acuático", 1))
Habitat <- factor(Habitat, levels = c("Subterráneo", "Acuático"))
Especie <- c(rep("EA14012-A", 17), rep("EA14013-B", 10))
datos2 <- data.frame(Especie, Habitat)
Ahora contamos las frecuencias y obtenemos la matriz de contingencia. Usamos las facilidades del paquete kableExtra para desplegar la tabla de forma más ordenada y legible.

tabla2 <- table(datos2)

Total2 <- apply(tabla2, 2, sum)
tabla2_total <- rbind(tabla2, Total = Total2)
tabla2_total |>
  kable(booktabs = TRUE, caption = "Frecuencias observadas") |>
  kable_styling(full_width = FALSE) |>
  kable_styling(bootstrap_options = c("striped")) |>
  row_spec(3, bold = TRUE) |>
  add_header_above(c("Especie", "Hábitats" = 2))
```
Frecuencias observadas
Especie
Hábitats
Subterráneo	Acuático
EA14012-A	5	12
EA14013-B	9	1
Total	14	13
Claramente no podemos usar una prueba de dos proporciones porque no se cumple la condición de éxito-fracaso (se espera observar al menos 10 éxitos y 10 fracasos en los datos). Así, solo nos queda respaldarnos en una prueba no paramétrica. En este caso, tratándose de muestras independientes, corresponde usar la prueba exacta de Fisher que nos permite responder (algo indirectamente) la pregunta planteada.

H0
: la proporción de hábitats preferidos es independiente de la especie de alienígena.

HA
: la proporción de hábitats preferidos depende de la especie de alienígena.

Tenemos una tabla de contingencia de 2x2 con las frecuencias observadas de dos variables dicotómicas en muestras aleatorias (al tratarse de un estudio serio), en que cada caso un espécimen alienígena puede ser contado solo en una celda a la vez. De esta forma, se cumplen las condiciones para aplicar la prueba.

Establecemos un nivel de significación y procedemos con la prueba.
```{r}
alfa2 <- 0.05
prueba2 <- fisher.test(tabla2, conf.level = 1 - alfa2)

cat("Resultado de la prueba exacta de Fisher:\n")
print(prueba2)
```
Resultado de la prueba exacta de Fisher:

    Fisher's Exact Test for Count Data

data:  tabla2
p-value = 0.004424
alternative hypothesis: true odds ratio is not equal to 1
95 percent confidence interval:
 0.0009844112 0.5436086585
sample estimates:
odds ratio 
0.05290488 

Interpretemos este resultado.
Vemos que el estadístico OR (odds ratio) está lejos del valor uno (OR=0,053;95%CI:[0,001;0,543]
) que indicaría igualdad, por lo que se rechaza la hipótesis nula en favor de la hipótesis alternativa (p=0,004
). En conclusión, la evidencia sugiere, con 95% de confianza, que las proporciones en que se prefieren hábitats subterráneos o acuáticos dependan de la especie alienígena del espécimen (EA14012-A o EA14013-B).

### Pregunta 3: Prueba de McNemar
#### Una organización dedicada a la rehabilitación de villanos ha observado que muchos de ellos ingresan al programa con niveles elevados de hostilidad. Para abordar este problema, decidieron implementar un nuevo programa de bienvenida diseñado para reducir la hostilidad y facilitar la reintegración a la sociedad. Para evaluar la efectividad de este programa, se reclutó a un grupo de 20 villanos a quienes se les midió el nivel de hostilidad (alto o bajo) antes y después de participar en el programa de bienvenida. Los resultados se presentan a continuación:

4 villanos no mostraron hostilidad ni antes ni después.
4 villanos que inicialmente mostraban hostilidad dejaron de hacerlo.
10 villanos mantuvieron un elevado nivel de hostilidad.
2 villanos que no mostraban hostilidad después del programa se volvieron hostiles.

¿Qué se puede concluir acerca de la efectividad del nuevo programa de bienvenida para reducir la hostilidad en los villanos?
En este caso tampoco podemos hacer una prueba de dos proporciones puesto que se trata de resultados sobre las mismas personas, por lo que las dos muestras están apareadas (no son independientes). Eso también descarta la prueba exacta de Fisher y una prueba χ2
 de Pearson. Como hay solo dos muestras, lo que corresponde es hacer una prueba de McNemar.

Planteemos las hipótesis:
H0
: los villanos tienen igual actitud antes y después del programa de bienvenida, es decir, la proporción de actitudes hostiles no cambia al participar del programa.

HA
: los villanos tienen distinta actitud antes y después del programa de bienvenida, es decir, la proporción de actitudes hostiles cambia al participar del programa.

Calculemos la tabla de frecuencias con el número de instancias en que los villanos consiguen resultados esperados del programas (bajan su hostilidad), cuando el villano no consigue los resultados esperados del programa (mantiene su alta hostilidad) y cuando sucede el resultado no esperado (un villano no hostil se vuelve hostil). Esto es sorprendentemente simple en R.
```{r}
# Definir los datos
antes <- c(rep("No Hostil", 4), rep("Hostil", 4), rep("Hostil", 10), rep("No Hostil", 2))
despues <- c(rep("No Hostil", 4), rep("No Hostil", 4), rep("Hostil", 10), rep("Hostil", 2))

# Crear el dataframe
datos3 <- data.frame(antes, despues)
tabla3 <- table(datos3)

Total <- apply(tabla3, 2, sum)
tabla3_total <- rbind(tabla3, Total)
tabla3_total |>
  kable(booktabs = TRUE, caption = "Frecuencias observadas") |>
  kable_styling(full_width = FALSE) |>
  kable_styling(bootstrap_options = c("striped")) |>
  row_spec(3, bold = TRUE) |>
  add_header_above(c("Antes del programa", "Después del programa" = 2))
```
Frecuencias observadas
Antes del programa
Después del programa
Hostil	No Hostil
Hostil	10	4
No Hostil	2	4
Total	12	8

Así tenemos una matriz de contingencia de 2x2 con las frecuencias de una variable categórica con dos niveles mutuamente exclusivos (“Hostil” o “No Hostil) en dos muestras pareadas formadas por pares seleccionados al azar (que asumimos al tratarse de una evaluación del programa a prueba). O sea que se cumplen las condiciones para aplicar la prueba de McNemar.

Establecemos un nivel de significación y procedemos con la prueba.
```{r}
alfa3 <- 0.05
prueba3 <- mcnemar.test(tabla3)

cat("Resultado de la prueba de McNemar:\n")
print(prueba3)
```
Resultado de la prueba de McNemar:

    McNemar's Chi-squared test with continuity correction

data:  tabla3
McNemar's chi-squared = 0.16667, df = 1, p-value = 0.6831

Contestemos la pregunta a la luz de este resultado.
Vemos que el estadístico es tiene un valor bajo (χ2
=0.167), indicando que las proporciones de villanos con actitudes hostiles son similares antes y después del programa de bienvenida, por lo que fallamos en rechazar la hipótesis nula (p=0,683
). Así, no hay razón para descartar que los villanos tienen la misma actitud tras el programa de bienvenida.

### Pregunta 4 : Prueba Q de Cochran
#### Una agencia de marketing desea determinar si hay una diferencia significativa en la efectividad de tres estrategias publicitarias utilizadas para promocionar un nuevo producto. Para ello, se ha recopilado información de los clientes que fueron expuestos a las tres estrategias publicitarias, registrando si mostraron una aceptación (A) o rechazo (R) a cada una de ellas. ¿Qué puede concluir la agencia de marketing sobre la efectividad de las estrategias publicitarias para promover el nuevo producto?
Indicación: obtenga la muestra de 50 clientes a partir del archivo “EP04 Datos.csv” que se encuentra en el directorio compartido, usando la semilla 255. Considere un nivel de significación α=0,05.

En esta pregunta se tiene una variable independiente (el cliente) que tiene tres observaciones pareadas de una variable de respuesta dicotómica (si acepta o rechaza cada una de las estrategias de publicidad).

Una herramienta que se conoce para este escenario es la prueba Q de Cochran, con las siguientes hipótesis:
H0
: la tasa de aceptación es la misma en las tres estrategias comerciales.

Ha
: al menos una de las estrategias de publicidad tiene una tasa de aceptación distinta a la de otra.

Obtengamos la muestra de datos.
```{r}
library(dplyr)

src_dir <- "~/Downloads"
src_basename <- "EP04 Datos.csv"
src_file <- file.path(src_dir, src_basename)
datos4 <- read.csv2(src_file)

set.seed(255)
muestra4 <- datos4 |> sample_n(size = 50, replace = FALSE)
```
Ahora se verifica si se cumplen las condiciones para poder aplicar la prueba con validez.

Por un lado, la variable de respuesta es dicotómica con niveles “A” (acepta) y “R” (rechaza) y la variable independiente es categórica cuyos niveles indican si se usa la estrategia de publicidad uno, dos o tres. Puesto que la muestra de clientes es seleccionada al azar y que el tamaño de la muestra (50) corresponde a menos del 10% de los potenciales clientes del producto, se puede asumir que las observaciones son independientes entre sí.

Por último, la muestra tiene 50 observaciones y tres niveles en la variable independiente, por lo que se cumple que 50⋅3=150≥24
, por lo que se verifica que la muestra es lo suficientemente grande.

En consecuencia, se cumplen todas las condiciones para usar la prueba Q de Cochran para este problema.

Llevamos los datos a formato largo, como requiere la implementación de esta prueba en el paquete RVAideMemoire de R.
```{r}
library(tidyr)

muestra_larga4 = muestra4 |> 
                 pivot_longer(c("estrategia_1", "estrategia_2", "estrategia_3"),
                             names_to = "Estrategias", values_to = "Evaluacion")
muestra_larga4[["Estrategias"]] = factor(muestra_larga4[["Estrategias"]])
Definimos el nivel de significación y llevamos a cabo la prueba Q de Cochran.

library(RVAideMemoire)

alfa4 <- 0.05
prueba4 = cochran.qtest(Evaluacion ~ Estrategias | id, data = muestra_larga4, alpha = alfa4)

cat("Resultado de la prueba Q de Cochran:\n")
prueba4
```
Resultado de la prueba Q de Cochran:

    Cochran's Q test

data:  Evaluacion by Estrategias, block = id 
Q = 1.0244, df = 2, p-value = 0.5992
alternative hypothesis: true difference in probabilities is not equal to 0 
sample estimates:
proba in group estrategia_1 proba in group estrategia_2 
                       0.56                        0.48 
proba in group estrategia_3 
                       0.46 
                       
Interpretemos estos resultados para responder la pregunta del enunciado.
La prueba Q de Cochran indica que no hay evidencia suficiente para rechazar la hipótesis nula en favor de la hipótesis alternativa (Q=1,024;p=0,599
), por lo que no existe evidencia para descartar que la tasa de aceptación es la misma para las estrategias publicitarias uno, dos y tres.

# Lectura 6: ANOVA para muestras independientes

Enunciado
En una emocionante competencia de cubos Rubik, participantes de Chile, Argentina, Colombia, Uruguay, Perú y Ecuador demostraron su destreza en resolver tres tipos de cubos: 2x2x2, 3x3x3 y Megaminx.

Después del torneo, un grupo de investigadores de la Asociación Mundial del Cubo, interesado en los tiempos que hicieron las jugadoras y los jugadores en la competencia, decidieron estudiar si el país y el tipo de cubo usado en cada prueba tienen influencia en los segundos que se tardan en resolverlos. Para ello usaron una muestra aleatoria de los datos de la competencia, en la cual participaron más de 2.000 personas, con las siguientes variables:
Descripción de los datos

Variable	Descripción
id	Identificador único de cada participante.

pais	País de procedencia de la persona (Argentina, Chile, Colombia, Ecuador, Perú, Uruguay).

tipo	Tipo de cubo usado en la prueba (2x2x2, 3x3x3 y Megaminx).

tiempo	Tiempo necesitado por cada participante en resolver el cubo de la prueba (en segundos).

### Pregunta: ¿Existen diferencias en el tiempo de resolución de cubos 3x3x3 entre participantes de Chile, Uruguay y Colombia?

En esta pregunta se pide inferir acerca de las medias de una variable numérica (tiempo) medidas en grupos independientes formados por un factor con tres niveles (país). Luego se requiere usar un procedimiento ANOVA para muestras independientes.

Las hipótesis serían:
H0
: los tiempos promedio requeridos para resolver un cubo de tipo 3x3x3 por las y los participantes de Chile (μCL
), Uruguay (μUY
) y Colombia (μCO
) son iguales; es decir (μCL=μUY=μCO
).

HA
: el tiempo promedio requerido para resolver un cubo de tipo 3x3x3 es diferente para las y los participantes de al menos uno de estos países (∃i,j∈{CL,UY,CO}:μi≠μj
).

Comencemos cargando los paquetes que vamos a utilizar.
```{r}
library(dplyr)
library(ez)
library(ggpubr)
Obtengamos la muestra de datos que debemos utilizar.

src_dir <- "~/Downloads"
src_basename <- "EP05 Datos.csv"
src_file <- file.path(src_dir, src_basename)
datos <- read.csv2(src_file, stringsAsFactors = TRUE)
datos[["id"]] <- factor(datos[["id"]])
Y seleccionemos datos de interés.

datos_largos <- datos |>
  filter(tipo == "3x3x3") |>
  filter(pais == "Chile" | pais == "Uruguay" | pais == "Colombia") |>
  select(id, pais, tiempo) |>
  droplevels()
datos_largos[["id"]] <- factor(datos_largos[["id"]])

# Mostramos las primeras filas para comprobar que todo va bien
head(datos_largos)
```
   id     pais tiempo
1  31    Chile  15.36
2  40  Uruguay  16.84
3  45 Colombia  16.48
4  76  Uruguay  16.64
5  94  Uruguay  16.14
6 142  Uruguay  16.43
Ahora verifiquemos las condiciones para asegurar que podemos aplicar el procedimiento con validez.

La variable dependiente corresponde a tiempo, que sabemos tiene escala de razón, y por lo tanto una escala continua de intervalos iguales, por ser una medida física.

Por otro lado, el enunciado indica que las observaciones son independientes entre sí, pues provienen de personas diferentes.

Revisemos ahora la condición de normalidad por medio de un gráfico Q-Q.
```{r}
g <- ggqqplot(datos_largos, x = "tiempo", y = "pais", color = "pais")

g <- g + facet_wrap(~ pais)
g <- g + rremove("x.ticks") + rremove("x.text")
g <- g + rremove("y.ticks") + rremove("y.text")
g <- g + rremove("axis.title")
print(g)
```

El gráfico generado muestra que la distribución de los datos de cada una de las muestras puede considerarse cercana a la normal pues, si bien no forman una recta, todos se encuentran dentro de la región aceptable del gráfico Q-Q y no se observan comportamientos extraños ni aleatorios.

De forma alternativa, podemos usar pruebas de normalidad para hacer esta verificación. Por el tamaño de las muestras disponibles aquí, sería apropiado aplicar la prueba de Shapiro-Wilk.
```{r}
# Realizar el test de Shapiro-test para cada país
tests_normalidad <- by(datos_largos[["tiempo"]],
                       datos_largos[["pais"]],
                       shapiro.test)
print(tests_normalidad)
```
datos_largos[["pais"]]: Chile

    Shapiro-Wilk normality test

data:  dd[x, ]
W = 0.98584, p-value = 0.8816

------------------------------------------------------------ 
datos_largos[["pais"]]: Colombia

    Shapiro-Wilk normality test

data:  dd[x, ]
W = 0.98293, p-value = 0.7961

------------------------------------------------------------ 
datos_largos[["pais"]]: Uruguay

    Shapiro-Wilk normality test

data:  dd[x, ]
W = 0.98744, p-value = 0.9443

Vemos que estas pruebas, de forma consistente con los gráficos Q-Q, descartan que debamos sospechar que alguna de estas muestras provenga de una población que no siga una distribución normal.

En cuanto a la condición de homocedasticidad, se posterga su discusión hasta ver el resultado de la prueba de Levene efectuada por ezAnova().

Puesto que hasta ahora no tenemos motivos que indiquen que los datos podrían incumplir alguna de las condiciones, podemos proceder con el procedimiento ANOVA para muestras independientes considerando un nivel de significación de 0,05.
```{r}
alfa <- 0.05

omnibus <- ezANOVA(
  data = datos_largos,
  dv = tiempo, between = pais, wid = id,
  return_aov = TRUE
)
```
Warning: Data is unbalanced (unequal N per group). Make sure you specified a
well-considered value for the type argument to ezANOVA().
Coefficient covariances computed by hccm()

Notemos los mensajes que nos presenta esta función. La primera nos advierte usar un “buen” valor para el argumento type debido a que las muestras tienen tamaños diferentes. En este caso no hemos cambiado el valor por omisión (type=2) que, como se dijo en el apunte, funciona para la mayoría de los casos (al menos al trabajar con un solo factor).

El segundo es menos importante y solamente nos informa de la función que está usando internamente para calcular la matriz de covarianzas.

Veamos el resultado del procedimiento por pantalla.
```{r}
cat("Resultado de la prueba de Levene:\n")
print(omnibus[2])
cat("Resultado de la prueba ANOVA:\n")
print(omnibus[1])
cat("Tabla ANOVA tradicional:\n")
print(summary(omnibus[["aov"]]))
```
Resultado de la prueba de Levene:
$`Levene's Test for Homogeneity of Variance`
  DFn DFd        SSn      SSd         F         p p<.05
1   2 115 0.05277397 4.024616 0.7539857 0.4727989      

Resultado de la prueba ANOVA:
$ANOVA
  Effect DFn DFd        F            p p<.05       ges
1   pais   2 115 103.5329 1.920038e-26     * 0.6429301

Tabla ANOVA tradicional:
             Df Sum Sq Mean Sq F value Pr(>F)    
pais          2  19.14   9.571   103.5 <2e-16 ***
Residuals   115  10.63   0.092                   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Podemos ver que la prueba de homocedasticidad de Levene resulta no significativa con 95% de confianza (F(2,115)=0,75;p=0,473
), por lo que se falla en rechazar la hipótesis nula de esta prueba, y debemos concluir que no hay suficiente evidencia para descartar que se cumple la condición de homocedasticidad en estos datos.

Interpretemos este resultado ómnibus.
El procedimiento ANOVA resultó significativo (F(2,115)=103,53;p<0,001
). En consecuencia, con 95% de confianza, rechazamos la hipótesis nula en favor de la hipótesis alternativa y concluimos que las y los participantes de al menos un país (Chile, Uruguay o Colombia) resolvieron en una cantidad de tiempo diferente los cubos de 3x3x3.

Puesto que el procedimiento ómnibus encuentra diferencias estadísticamente significativas, es necesario realizar un procedimiento post-hoc. Puesto que no requerimos hacer contrastes adicionales, usaremos la prueba HSD de Tukey, más poderosa que los factores de corrección no paramétricos (como el de Holm o el de Benjamini y Hochberg), ya que no se ha descartado que los datos siguen distribuciones normales y con igual varianza.
```{r}
post_hoc <- TukeyHSD(omnibus[["aov"]], which = "pais",
                     ordered = TRUE, conf.level = 1 - alfa)
print(post_hoc)
  Tukey multiple comparisons of means
    95% family-wise confidence level
    factor levels have been ordered
```
Fit: aov(formula = formula(aov_formula), data = data)

$pais
                      diff       lwr       upr p adj
Colombia-Chile   0.4646037 0.3041585 0.6250488     0
Uruguay-Chile    0.9920699 0.8283654 1.1557743     0
Uruguay-Colombia 0.5274662 0.3627939 0.6921385     0

Podemos ver una representación gráfica del efecto encontrado en este análisis (producido en la variable dependiente tiempo por la variable independiente país).
```{r}
g_efecto <- ezPlot(data = datos_largos, x = pais,
                   dv = tiempo, wid = id, between = pais,
                   y_lab = " Tiempo para resolver cubos de 3x3x3 [s]")
Warning: Data is unbalanced (unequal N per group). Make sure you specified a
well-considered value for the type argument to ezANOVA().
Coefficient covariances computed by hccm()
Warning in ezStats(data = data, dv = dv, wid = wid, within = within,
within_full = within_full, : Unbalanced groups. Mean N will be used in
computation of FLSD
g_efecto <- g_efecto + theme_pubr()
print(g_efecto)
```

Vemos que el gráfico del efecto coincide con los resultados de la prueba post-hoc, mostrando con claridad diferencias entre participantes de los países estudiados. Concluyamos con todos estos resultados.
El análisis post-hoc indica que participantes provenientes de Uruguay son más lentos que quienes vienen de Colombia al resolver un cubo de 3x3x3 (95% IC: [0,363; 0,692] s, p<0,001
), que a su vez son más lentos que participantes de Chile (95% IC: [0,304; 0,625] s, p<0,001
).

# Lectura 7: ANOVA para muestras correlacionadas

Enunciado
Un equipo de investigación del área de interacción humano-información está estudiando si el área temática y el nivel de dificultad del problema de información influyen en el tiempo (en segundos) que le toma a una persona en formular una consulta de búsqueda para resolver dicho problema.

Para ello, han reclutado a un grupo voluntario de participantes, asignados aleatoriamente a distintos grupos. Cada participante debe resolver tres problemas de información con diferentes niveles de dificultad: baja, media y alta. A su vez, cada grupo debe resolver problemas relacionados a una temática diferente. Los datos recolectados contemplan las siguientes variables:

Descripción de los datos
Variable	Descripción
id	Identificador único de cada participante.

area	Área temática de los problemas que cada participante debe responder. Variable categórica con los niveles Arquitectura, Biología, Computación, Economía, Física, Leyes, Literatura, Matemáticas, Música, Pedagogía, Psicología, Química.

dificultad	Nivel de dificultad del problema resuelto. Variable categórica con los niveles Baja, Media y Alta.

tiempo	Tiempo, en segundos, que toma a cada participante formular la consulta

En este momento, el equipo de investigación busca determinar si existen diferencias en el tiempo que tardan las personas en formular consultas para problemas con diferentes niveles de dificultad en el área de matemáticas.

En esta pregunta se pide inferir acerca de medias de una variable numérica (tiempo) medida en condiciones distintas (niveles de dificultad) para un conjunto de las mismas personas, lo que correlaciona las mediciones. Luego se requiere usar un procedimiento ANOVA para muestras correlacionadas. Las hipótesis serían:
H0
: no hay diferencia en los tiempos requeridos por las mismas personas para formular consultas asociadas a un problema de información en el área de las matemáticas al considerar niveles de dificultad bajo (B)
, medio (M)
 y alto (A)
; es decir: μ(B−M)=μ(B−A)=μ(M−A)=0
.

HA
: hay diferencia en los tiempos requeridos por las mismas personas para formular consultas asociadas a problemas de información en el área de las matemáticas con diferentes niveles de dificultad, es decir ∃i,j∈{B,M,A}:μ(i−j)≠0
.

Comencemos cargando los paquetes que vamos a utilizar.
```{r}
library(dplyr)
library(emmeans)
library(ez)
library(ggpubr)
library(nlme)
```
Luego, obtengamos la muestra de datos (desde el archivo disponible para el ejercicio práctico anterior) que debemos utilizar.
```{r}
src_dir <- "~/Downloads"
src_basename <- "EP06 Datos.csv"
src_file <- file.path(src_dir, src_basename)
datos <- read.csv(file = src_file, stringsAsFactors = TRUE)
Y seleccionemos datos de interés, aprovechando de especificar el orden deseado de los niveles del factor (que por defecto, R ordena alfabéticamente).

# Los datos ya vienen en formato largo
datos_largos <- datos |>
  filter(area == "Matemáticas") |>
  select(id, dificultad, tiempo) |>
  droplevels()
datos_largos[["id"]] <- factor(datos_largos[["id"]])
datos_largos[["dificultad"]] <- factor(datos_largos[["dificultad"]],
                                       levels = c("Baja", "Media", "Alta"))

# Mostramos las primeras filas para comprobar que todo va bien
head(datos_largos)
```
  id dificultad tiempo
1 17       Baja     93
2 17      Media     97
3 17       Alta     92
4 24       Baja     67
5 24      Media     95
6 24       Alta     91

Procedemos a verificar las condiciones para asegurar que podemos aplicar el procedimiento para muestras correlacionadas con validez.

La variable dependiente corresponde a tiempo que, como vimos, se mide en una escala continua de intervalos iguales.

Por otro lado, los tríos de observaciones son independientes entre sí, pues provienen de personas diferentes que fueron elegidos de manera aleatoria.

Revisemos ahora la condición de normalidad por medio de un gráfico Q-Q.
```{r}
g <- ggqqplot(datos_largos, x = "tiempo", y = "dificultad",
              color = "dificultad")

g <- g + facet_wrap(~ dificultad)
g <- g + rremove("x.ticks") + rremove("x.text")
g <- g + rremove("y.ticks") + rremove("y.text")
g <- g + rremove("axis.title")
print(g)
```

El gráfico sugiere que los datos siguen una distribución cercana a la normal, puesto que se encuentran dentro de la región aceptable del gráfico Q-Q y no se observan patrones no aleatorios, aunque se observa cierta desviación en el extremo superior de las preguntas con dificultad alta. Conviene entonces que usemos pruebas de normalidad para confirmar.
```{r}
# Realizar el test de Shapiro-test para cada país
tests_normalidad <- by(datos_largos[["tiempo"]],
                       datos_largos[["dificultad"]],
                       shapiro.test)
print(tests_normalidad)
```
datos_largos[["dificultad"]]: Baja

    Shapiro-Wilk normality test

data:  dd[x, ]
W = 0.99652, p-value = 0.9344

------------------------------------------------------------ 
datos_largos[["dificultad"]]: Media

    Shapiro-Wilk normality test

data:  dd[x, ]
W = 0.99093, p-value = 0.2436

------------------------------------------------------------ 
datos_largos[["dificultad"]]: Alta

    Shapiro-Wilk normality test

data:  dd[x, ]
W = 0.99442, p-value = 0.6629

Vemos que estas pruebas de Shapiro-Wilk descartan que debamos temer que alguna de estas muestras no provenga de una población con una distribución normal.

En cuanto a la condición de esfericidad, se posterga su discusión hasta ver el resultado de la prueba de Mauchly efectuada por ezAnova().

Así, vamos a proceder con el procedimiento ANOVA para muestras correlacionadas considerando un nivel de significación de 0,05.
```{r}
alfa <- 0.05

omnibus <- ezANOVA(
  data = datos_largos,
  dv = tiempo, within = dificultad, wid = id,
  return_aov = TRUE
)
Veamos el resultado del procedimiento por pantalla.

cat("Resultado de la prueba de Mauchly:\n\n")
print(omnibus[2])
cat("Resultado de la prueba ANOVA:\n\n")
print(omnibus[1])
cat("Tabla ANOVA tradicional:\n")
print(summary(omnibus[["aov"]]))
```
Resultado de la prueba de Mauchly:

$`Mauchly's Test for Sphericity`
      Effect         W         p p<.05
2 dificultad 0.9849307 0.2224141      

Resultado de la prueba ANOVA:

$ANOVA
      Effect DFn DFd        F            p p<.05       ges
2 dificultad   2 398 114.8477 4.213847e-40     * 0.2827608

Tabla ANOVA tradicional:

Error: id
           Df Sum Sq Mean Sq F value Pr(>F)
Residuals 199  11233   56.45               

Error: id:dificultad
            Df Sum Sq Mean Sq F value Pr(>F)    
dificultad   2  13974    6987   114.8 <2e-16 ***
Residuals  398  24214      61                   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Podemos ver que la prueba de esfericidad de Mauchly resulta no significativa con 97,5% de confianza (W=0,985;p=0,222
), por lo que se falla en rechazar la hipótesis nula de esta prueba. Así, debemos concluir que no hay suficiente evidencia estadística para descartar que se cumple la condición de esfericidad en estos datos.

Interpretemos este resultado ómnibus.
El procedimiento ANOVA correlacionado resultó significativo (F(2,398)=114,848;p<0,001
). En consecuencia, con 95% de confianza, rechazamos la hipótesis nula en favor de la hipótesis alternativa y concluimos que hay diferencias en el tiempo requerido por las mismas personas para formular consultas asociadas a un problema de información de en el área de las matemáticas con diferentes niveles de dificultad (baja, media y alta).

Puesto que el procedimiento ómnibus encuentra diferencias estadísticamente significativas, es necesario realizar un procedimiento post-hoc. Puesto que no requerimos hacer contrastes adicionales, usaremos la prueba HSD de Tukey (haciendo uso de un modelo mixto y de la estimación de medias marginales, implementadas en R en los paquetes nlme y emmeans respectivamente).

```{r}
mixto <- lme(tiempo ~ dificultad , data = datos, random = ~1 | id)
medias <- emmeans (mixto , "dificultad")
post_hoc <- pairs(medias , adjust = "tukey")
conf_int <- confint(post_hoc, level = 1 - alfa)

print(post_hoc)
print(conf_int)
```
 contrast     estimate    SE   df t.ratio p.value
 Alta - Baja     6.244 0.238 4398  26.232  <.0001
 Alta - Media    5.338 0.238 4398  22.428  <.0001
 Baja - Media   -0.905 0.238 4398  -3.804  0.0004

Degrees-of-freedom method: containment 
P value adjustment: tukey method for comparing a family of 3 estimates 
 contrast     estimate    SE   df lower.CL upper.CL
 Alta - Baja     6.244 0.238 4398     5.69    6.802
 Alta - Media    5.338 0.238 4398     4.78    5.896
 Baja - Media   -0.905 0.238 4398    -1.46   -0.347

Degrees-of-freedom method: containment 
Confidence level used: 0.95 
Conf-level adjustment: tukey method for comparing a family of 3 estimates 

Veamos si estos resultados coincide con el efecto (que tiene la variable independiente dificultad en la variable dependiente tiempo) encontrado en el procedimiento ANOVA para muestras correlacionadas.

```{r}
g_efecto <- ezPlot(data = datos_largos, x = dificultad,
                   dv = tiempo, within = dificultad, wid = id,
                   y_lab = " Tiempo requerido para formular consultas [s]"
)
print(g_efecto)
```

Vemos que el gráfico del efecto coincide bien con los resultados de la prueba post-hoc. Redactemos la conclusión.
El análisis post-hoc usando el método de la diferencia honestamente significativa de Tukey indica que, en el área de las matemáticas, el tiempo requerido por una persona para formular consultas aumenta con el nivel de dificultad del problema de información (Alta-Baja: 95% CI: [5,69; 6,80], t(4.398)=26,232,p<0,001
; Alta-Media: 95% CI: [4,78; 5,90], t(4.398)=22.428,p<0,001
; Media-Baja: 95% CI: [0,35; 1,46], t(4.398)=3.804,p<0,001
).

# Lectura 8: Transformación de datos

# Lectura 9 y 10: Pruebas no paramétricas para datos problematicos

Enunciado
En el trabajo de título de una estudiante del DIINF se reportan tiempos de ejecución (en milisegundos) y la cercanía con la solución óptima (en por ciento) de la mejor solución encontrada con tres versiones de un algoritmo genético para resolver instancias del problema del vendedor viajero disponibles en repositorios públicos. Ahora debe enfrentar el análisis de estos datos, por que está solicitando ayuda de las y los estudiantes de Estadística Inferencial.

Comencemos cargando los paquetes que vamos a utilizar.
```{r}
library(dplyr)
library(ggpubr)
library(tidyr)
```
Y cargando los datos.
```{r}
src_dir <- "~/Downloads"
src_basename <- "EP07 Datos.csv"
src_file <- file.path(src_dir, src_basename)
datos <- read.csv(file = src_file, stringsAsFactors = TRUE)

# Revisamos lo leído
print(head(datos))
```
  instancia n.nodos n.aristas tiempo.A tiempo.B tiempo.C mejor.A mejor.B
1         1      50       631   107534   452595   257485   98.72   98.25
2         2      50       521    74808   364061   207297   98.99   99.17
3         3      50       588    94072   417798   237793   99.10   99.23
4         4      50       653   114830   470701   267598   98.69   99.23
5         5      50       597    96720   425233   241770   99.80   99.22
6         6      50       564    86688   398448   226833   99.19   99.15
  mejor.C
1   99.34
2   99.48
3   99.10
4   97.82
5   98.14
6   98.04
Vemos que los datos se leyeron adecuadamente y que vienen en formato ancho.

### Pregunta 1
#### Observando los datos, la memorista sospecha que hay diferencias significativas en el tiempo de ejecución entre las versiones A y C del algoritmo cuando las instancias tienen 100 o más nodos. ¿Los datos respaldan la intuición de la memorista?

Para responder, filtren los datos para tener las instancias con 100 o más nodos y seleccionen las columnas de los tiempos de ejecución de las versiones A y C en formato ancho. Usando como semilla el valor 213, obtengan muestras aleatorias independientes de 20 tiempos registrados por la versión A y 18 tiempos registrados por la versión C del algoritmo. Realicen un análisis estadístico pertinente (enunciar hipótesis, revisar condiciones, seleccionar prueba) para responder la pregunta planteada, utilizando pruebas no paramétricas de ser necesario.

Primero, filtramos para quedarnos con las instancias que nos interesan y quitar las columnas que no necesitamos. También obtenemos la puestra en formato largo para las funciones que las necesitan de esa manera
```{r}
set.seed(213)
muestra_1 <- datos |>
  filter(n.nodos >= 100) |>
  select(instancia, tiempo.A, tiempo.C) |>
  sample_n(20 + 18)

instancia <- muestra_1 |> pull(instancia)
tiempo_A <- muestra_1 |> slice(1:20) |> pull(tiempo.A)
tiempo_C <- muestra_1 |> slice(21:(20 + 18)) |> pull(tiempo.C)
version <- c(rep("A", 20), rep("C", 18))
tiempo <- c(tiempo_A, tiempo_C)

datos_1_largos <- data.frame(instancia, version, tiempo) |>
  mutate(instancia = factor(instancia)) |>
  mutate(version = factor(version))
```
Como es aconsejado, echemos un vistazo a los datos que se están trabajando.
```{r}
# Llevamos los tiempos a minutos para mejor legibilidad
datos_1_largos <- datos_1_largos |>
  mutate(minutos = tiempo / 1000 / 60)

# Creamos y mostramos el gráfico
p1 <- gghistogram(datos_1_largos, x = "minutos",
                  xlab = "Tiempo [minutos]",  ylab = "Frecuencia",
                  color = "version", fill = "version",
                  bins = 10)
p1 <- p1 + facet_grid(~ version)
print(p1)
```

Podemos ver que las muestras no parecen tomadas desde una distribución normal, lo que podemos confirmar con pruebas auxiliares de normalidad.
```{r}
print(shapiro.test(tiempo_A))
print(shapiro.test(tiempo_C))
```
    Shapiro-Wilk normality test

data:  tiempo_A
W = 0.94634, p-value = 0.3149


    Shapiro-Wilk normality test

data:  tiempo_C
W = 0.79917, p-value = 0.001478

Se confirma que hay una fuerte evidencia de que los tiempos exhibidos por la versión C no provienen de una distribución normal (W=0,799
; p=0,001
). Corresponde entonces usar una prueba no paramétrica para analizar estos datos. En este caso, una prueba de Wilcoxon-Mann-Whitney, en reemplazo de una prueba t de Student para muestras independientes.

Como vimos, las hipótesis contrastadas por esta prueba depende de la forma de las distribuciones de las poblaciones desde donde provienen las muestras. Mirando el histograma, no parece que estas poblaciones se podrían distribuir de manera similar. Esto, lo podemos corroborar con una prueba auxiliar: la prueba de Kolmogorov–Smirnov, que es una prueba no paramétrica que evalúa la hipótesis nula de que ambas muestras provienen de distribuciones iguales (unidimensionales, continuas u ordinales) (Berger & Zhou, 2014). Esta prueba puede accederse en R a través de la función ks.test(x, y, alternative = c("two.sided", "less", "greater")), como muestra el siguiente código.

```{r}
print(ks.test(tiempo_A, tiempo_C))
```

    Exact two-sample Kolmogorov-Smirnov test

data:  tiempo_A and tiempo_C
D = 0.69444, p-value = 5.124e-05
alternative hypothesis: two-sided

Vemos que hay evidencia suficiente (D=0,694
; p≪0,001
) para descartar que las muestras provienen de distribuciones iguales, por lo que las hipótesis no podrían referirse a medianas. Así, enunciamos las siguientes hipótesis:
H0
: no hay diferencia en los tiempos de ejecución requeridos por las versiones A y C del algoritmo para instancias con 100 o más nodos.

HA
: los tiempos de ejecución requeridos por ambas versiones para instancias con 100 o más nodos son distintos.

Verifiquemos que se cumplen las condiciones para aplicar esta prueba no paramétrica con validez:

Las observaciones de ambas muestras son independientes. De como hicimos el muestreo más arriba, podemos asegurar que las muestras fueron escogidas de forma aleatoria y no comparten alguna instancia.
La escala de medición empleada debe ser a lo menos ordinal. Como la variable en estudio es de tiempo, que corresponde a una medición física, la escala de la medición cumple con condiciones más exigente que solo la ordinal, y tiene sentido hablar de “más/igual/menos tiempo”.
Como se cumplen bien las condiciones, usemos el típico nivel de significación α=0,05
 Procedamos entonces a realizar la prueba.
```{r}
alfa <- 0.05
prueba_1 <- wilcox.test(tiempo_A, tiempo_C,
                        paired = FALSE)
print(prueba_1)
```
    Wilcoxon rank sum exact test

data:  tiempo_A and tiempo_C
W = 310, p-value = 6.053e-05
alternative hypothesis: true location shift is not equal to 0

Podemos concluir:
Existe fuerte evidencia en contra de la hipótesis nula (W=310;p≪0,001
), por lo que la rechazamos en favor de la alternativa. Esto es, los tiempos que tarda la versión A del algoritmo en resolver instancias con 100 o más nodos del problema del vendedor viajero son distintos a los que tarda la versión C. Mirando los histogramas de los datos, podemos sugerir que el algoritmo C requiere, en promedio, significativamente menos tiempo de procesamiento.

### Pregunta 2
#### La memorista también sospecha que, al comparar las mismas instancias con 70 a 85 nodos, las mejores soluciones encontradas por las versiones B y C tienen rendimientos distintos. ¿Estará en lo cierto?

Para responder, filtren los datos para tener las instancias que tengan de 70 a 85 nodos y seleccionen las columnas con el mejor rendimiento de las versiones B y C en formato ancho. Usando como semilla el valor 117, obtengan una muestra aleatoria de 24 instancias. Lleven los datos a formato largo y utilicen una prueba no paramétrica apropiada para analizar las muestras obtenidas.

Obtenemos la muestra de datos que se nos indica. Como tenemos que comparar los resultados obtenidos por los algoritmos con las mismas instancias, debemos obtener una muestra apareada de 24 observaciones.
```{r}
set.seed(117)

muestra_2 <- datos |>
  filter(n.nodos >= 70, n.nodos <= 85) |>
  select(instancia, mejor.B, mejor.C) |>
  sample_n(24)

datos_2_largos <- muestra_2 |>
  pivot_longer(-instancia, names_to = "version",
               names_pattern = "mejor[.](.*)",
               values_to = "mejor_sol") |>
  mutate(instancia = factor(instancia)) |>
  mutate(version = factor(version))
```
Revisemos los datos con un diagrama de cajas.
```{r}
p2 <- ggboxplot(datos_2_largos,
                x = "version", y = "mejor_sol", fill = "version", 
                xlab = "Versión del algoritmo",
                ylab = "Mejor resultado (% del óptimo)")
print(p2)
```

Vemos que los datos para el algoritmo B presentan una leve asimetría y la presencia de valores atípicos. Además, se está trabajando con porcentajes, que tiene un rango de valores limitado al intervalo [0, 100], lo que usualmente viola la idea de variable continua. Sería prudente, entonces, utilizar una prueba no paramétrica para el análisis, como alternativa a una prueba t de Student para muestras apareadas, que en este caso correspondería a una prueba de rangos con signo de Wilcoxon.

Si miramos con cuidado el diagrama de cajas, vemos que las muestras parecen seguir distribuciones con el mismo tipo de asimetría. Usemos la prueba de Kolmogorov–Smirnov para corroborar esta sospecha.

print(ks.test(muestra_2[["mejor.B"]], muestra_2[["mejor.C"]]))

    Exact two-sample Kolmogorov-Smirnov test

data:  muestra_2[["mejor.B"]] and muestra_2[["mejor.C"]]
D = 0.16667, p-value = 0.8891
alternative hypothesis: two-sided

Vemos, entonces, que hay no evidencia que permita descartar que las mejores soluciones para las mismas instancias de prueba que consiguen las versiones B y C del algoritmo se distribuyen de igual forma (D=0,167
; p=0,889
). Con este resultados, la prueba puede interpretarse como una comparación de medianas con las siguientes hipótesis (bilaterales):
H0
: no hay diferencia en las medianas de la calidad de las mejores soluciones encontradas por las versiones B y C del algoritmo en las mismas instancias con 70 a 85 nodos.

HA
: sí hay diferencias en las medianas de la calidad de las mejores soluciones obtenidas por ambas versiones del algoritmo en las mismas instancias con 70 a 85 nodos.

Verifiquemos las condiciones:

Los pares de observaciones son independientes. Efectivamente, si el experimento fue realizado correctamente por la memorista, cómo se desempeña un algoritmo no debería tener influencia en cómo rinde el segundo.
La escala de medición empleada para ambas muestras debe ser a lo menos ordinal. Valores porcentuales cumplen esta condición, pues podemos compararlos y ordenarlos.
Procedamos con la prueba no paramétrica, con el nievel de significación usual, ya que se cumplen todas las condiciones.
```{r}
alfa <- 0.05
prueba_2 <- wilcox.test(muestra_2[["mejor.B"]],
                        muestra_2[["mejor.C"]],
                        paired = TRUE)
print(prueba_2)
```
    Wilcoxon signed rank exact test

data:  muestra_2[["mejor.B"]] and muestra_2[["mejor.C"]]
V = 167, p-value = 0.6431

alternative hypothesis: true location shift is not equal to 0
Concluyamos a la luz de estos resultados.
La prueba de rangos con signo de Wilcoxon falla en rechazar la hipótesis nula (V=167
; p=0,643
). Así, no es posible descartar que la calidad (cercanía con la solución óptima) de las mejores soluciones conseguidas por la versión B del algoritmo tiene la misma mediana que las obtenidas por la versión C en las mismas instancias con 70 a 85 nodos.



### Pregunta 3
#### La memorista además cree que hay diferencias significativas en el tiempo de ejecución entre las versiones del algoritmo cuando las instancias de prueba tienen 100 o más nodos. ¿Los datos respaldan la intuición de la memorista?

Para responder, filtren los datos para tener las instancias con 100 o más nodos y seleccionen las columnas con los tiempos de ejecución registrados (en formato ancho). Usando como semilla el valor 33, obtengan muestras aleatorias independientes de 12, 13 y 14 tiempos registrados por las versiones A, B y C, respectivamente. Lleven los datos a formato largo y utilicen una prueba no paramétrica para analizar las muestras obtenidas.

Primero, filtramos para quedarnos con las instancias que nos interesan y quitar las columnas que no necesitamos, siguiendo las instrucciones dadas.
```{r}
set.seed(33)

muestra_3 <- datos |>
  filter(n.nodos >= 100) |>
  select(instancia, tiempo.A, tiempo.B, tiempo.C) |>
  sample_n(12 + 13 + 14)

instancia <- muestra_3 |> pull(instancia)
tiempo_A <- muestra_3 |> slice(1:12) |> pull(tiempo.A)
tiempo_B <- muestra_3 |> slice(13:(12+13)) |> pull(tiempo.B)
tiempo_C <- muestra_3 |> slice((12+13+1):(12+13+14)) |> pull(tiempo.C)
version <- c(rep("A", 12), rep("B", 13), rep("C", 14))
tiempo <- c(tiempo_A, tiempo_B, tiempo_C)

datos_3_largos <- data.frame(instancia, version, tiempo) |>
  mutate(instancia = factor(instancia)) |>
  mutate(version = factor(version))
```
Puesto que cada muestra contiene instancias de prueba distintas, la primera alternativa sería usar ANOVA de una vía para muestras independientes para este análisis. Esta prueba permitiría determinar si la memorista tiene o no razón en pensar que existen diferencias significativas en los tiempos medios de ejecución de los algoritmos.

Verificamos las condiciones:

Existe independencia entre las muestras, pues no hay elementos en común y el tiempo que tarda una versión del algoritmo en alguna de las instancias escogida no debería influir en el tiempo que tarda otra versión en otra instancia.
También se cumple que la variable dependiente tiene una escala de intervalos iguales, pues es una medición física (tiempo).
Veamos si se cumple con las condiciones de normalidad y homocedasticidad por medio de histogramas.
```{r}
# Llevamos los tiempos a minutos para mejor legibilidad
datos_3_largos <- datos_3_largos |>
  mutate(minutos = tiempo / 1000 / 60)

# Creamos y mostramos el gráfico
p3 <- gghistogram(
  datos_3_largos, x = "minutos",
  color = "version", fill = "version", bins = 10,
  xlab = "Tiempo [minutos]", ylab = "Frecuencia")
p3 <- p3 + facet_grid(~ version)
print(p3)
```

Podemos ver que las muestras no siguen un comportamiento aproximadamente normal, por lo que no podríamos suponer razonablemente que las poblaciones de donde provienen sí tengan dicha distribución.

Como el problema no parece requerir un valor de las medias estudiadas, sería conveniente bajar las exigencias y optar por una prueba no paramétrica, como se nos indica en el enunciado. En este caso, correspondería una prueba de Kruskal-Wallis.

Del histograma, tampoco podríamos suponer que las formas de las distribuciones subyacentes sean iguales, por lo que las hipótesis no podrían referirse a medianas. Así, las hipótesis no paramétricas a contrastar serían:
H0
: todas las versiones del algoritmo tardan tiempos similares en resolver instancias del problema del vendedor viajero con 100 o más nodos.

HA
: al menos uno de las versiones del algoritmo exhibe tiempos de ejecución significativamente distintos a (al menos) una de las otras versiones para resolver instancias con 100 o más nodos.

Verifiquemos las condiciones:

Ya sabemos que existe independencia ente las observaciones.
También se verifica que la variable independiente tiene más de dos niveles (versiones A, B y C).
Por último, la escala de la variable dependiente debe ser al menos ordinal, y sabemos que las mediciones físicas cumplen de sobra con tal condición.
Aplicamos la prueba, con el nivel de significación más común.
```{r}
alfa <- 0.05
prueba_3 <- kruskal.test(tiempo ~ version, data = datos_3_largos)

print(prueba_3)
```
    Kruskal-Wallis rank sum test

data:  tiempo by version
Kruskal-Wallis chi-squared = 19.802, df = 2, p-value = 5.012e-05
Escribamos la conclusión ómnibus.
La prueba indica que hay suficiente evidencia para rechazar la hipótesis nula en favor de la hipótesis alternativa (χ2=19,80
; p≪0,001

). En consecuencia, podemos concluir con 95% de confianza que al menos una de las versiones del algoritmo difiere significativamente en el tiempo que tarda en resolver las instancias del problema del vendedor viajero con 100 o más nodos.

Como la prueba ómnibus de Kruskal-Wallis detecta diferencias, debemos hacer ahora un procedimiento post-hoc. Para ello usaremos múltiples pruebas de Wilcoxon-Mann-Whitney entre pares de grupos, aplicando el ajuste de Benjamini & Hochberg (1995) por tener mayor poder estadístico que varios otros métodos.
```{r}
posthoc_3 <- pairwise.wilcox.test(tiempo, version, paired = FALSE,
                                  p.adjust.method = "BH")
print(posthoc_3)
```
    Pairwise comparisons using Wilcoxon rank sum exact test 

data:  tiempo and version 

  A       B      
B 0.64951 -      
C 0.00037 1.3e-05

P value adjustment method: BH 

Ahora podemos hacer la conclusión completa.
El procedimiento post-hoc no encuentra diferencias significativas entre las versiones A y B del algoritmo (p=0,650
), pero estas dos versiones parecen tardar significativamente más que la versión C (p<0,001
) en resolver instancias del problema del vendedor viajero con 100 o más nodos.



### Pregunta 4
#### La memorista también intuye que, al comparar las mismas instancias de prueba con 100 o más nodos, las mejores soluciones encontradas por las diferentes versiones del algoritmo tienen rendimientos distintos. ¿Estará en lo cierto?

Para responder, filtren los datos para tener las instancias con 100 o más nodos y seleccionen las columnas con los mejores rendimientos registrados. Usando como semilla el valor 33, obtengan una muestra aleatoria de 26 instancias. Lleven los datos a formato largo y utilicen una prueba no paramétrica apropiada para analizar los datos obtenidos.

Obtenemos la muestra de datos en formato ancho. Como tenemos que comparar los resultados obtenidos por los algoritmos con las mismas instancias, debemos obtener una muestra apareada de 26 observaciones.
```{r}
set.seed(33)

muestra_4 <- datos |>
  filter(n.nodos >= 100) |>
  select(instancia, mejor.A, mejor.B, mejor.C) |>
  sample_n(26)

datos_4_largos <- muestra_4 |>
  pivot_longer(-instancia, names_to = "version",
               names_pattern = "mejor[.](.*)",
               values_to = "mejor_sol") |>
  mutate(instancia = factor(instancia)) |>
  mutate(version = factor(version))
```
Puesto que cada muestra contiene la calidad de la solución obtenida por cada versión del algoritmo al resolver las mismas instancias de prueba, correspondería usar ANOVA de una vía para medidas repetidas, que permitiría determinar si la memorista tiene o no razón en pensar que existen diferencias significativas entre las versiones.

Revisemos los datos con un diagrama de cajas.
```{r}
p4 <- ggboxplot(datos_4_largos,
                x = "version", y = "mejor_sol", fill = "version",
                xlab = "Versión del algoritmo",
                ylab = "Mejor resultado (% del óptimo)")
print(p4)
```

Vemos que existen ciertas asimetrías y algunos valores atípicos en los datos. Además, por la forma de las cajas, parece improbable que estos datos cumplan la condición de esfericidad. Y como notamos anteriormente, la calidad de las soluciones se mide como el porcentaje de cercanía con la solución óptima, por lo que la variable tiene un rango limitado. Por todas estas razones, preferimos usar una prueba no paramétrica, como nos instruye el enunciado. Al tratarse de medidas repetidas y más de dos grupos, corresponde usar la prueba de Friedman.

Verificamos las condiciones:

La variable independiente es categórica y tiene a lo menos tres niveles: versiones A, B y C del algoritmo.
Las tripletas de observaciones son independientes pues, si el experimento fue realizado correctamente, el desempeño en una instancia de prueba específica no debería tener influencia en el rendimiento que se alcance en otra.
La escala de la variable dependiente es a lo menos ordinal, pues valores porcentuales se pueden comparar y ordenar.
En consecuencia, se cumplen las condiciones para aplicar la prueba de Friedman. Como las muestras presentan evidentes diferencias de varianzas, no podríamos confiar en que las poblaciones subyacentes se distribuyan de forma equivalente. Por lo tanto, no podemos inferir sobre las medianas de las poblaciones y contrastamos las siguientes hipótesis no paramétricas:
H0
: la calidad de las mejores soluciones conseguidas para las mismas instancias de prueba con 100 o más nodos por las tres versiones del algoritmo son similares.

HA
: al menos una de las versiones del algoritmo entrega mejores soluciones con calidad significativamente distinta que al menos otra versión al resolver las mismas instancias del problema del vendedor viajero con 100 o más nodos.

Aplicamos la prueba con un nivel de significación exigente por la dispersión heterogénea de las muestras y la presencia de valores atípicos (α=0,01
).
```{r}
alfa <- 0.01
prueba_4 <- friedman.test(mejor_sol ~ version | instancia,
                          data = datos_4_largos)

print(prueba_4)
```
    Friedman rank sum test

data:  mejor_sol and version and instancia
Friedman chi-squared = 21.689, df = 2, p-value = 1.951e-05
Podemos hacer la conclusión ómnibus.
La prueba de Friedman indica que hay suficiente evidencia (χ2=21,69
; p≪0,001
) para rechazar la hipótesis nula en favor de la alternativa. En consecuencia, podemos concluir con 99% de confianza que al menos una de las versiones estudiadas del algoritmo tiene un rendimiento distinto a alguna de las otras o a ambas.

Puesto que la prueba ómnibus (de Friedman) detecta diferencias, debemos hacer ahora un procedimiento post-hoc usando múltiples pruebas de rangos con signo de Wilcoxon entre pares de grupos y, al igual que en la pregunta anterior, aplicando el ajuste de Benjamini & Hochberg (1995).
```{r}
posthoc_4 <- pairwise.wilcox.test(datos_4_largos[["mejor_sol"]],
                                  datos_4_largos[["version"]],
                                  paired = TRUE, p.adjust.method = "BH")
Warning in wilcox.test.default(xi, xj, paired = paired, ...): cannot compute
exact p-value with zeroes
print(posthoc_4)
```
    Pairwise comparisons using Wilcoxon signed rank exact test 

data:  datos_4_largos[["mejor_sol"]] and datos_4_largos[["version"]] 

  A       B     
B 2.2e-06 -     
C 0.0025  0.0382

P value adjustment method: BH 
Por ahora vamos a ignorar el warning que nos da la función, puesto que sabemos que si hay empates, el algoritmo interno de esta prueba los descarta antes del cálculo de los rangos. Si fuéramos muy rigorosos, deberíamos revisar que no son tantos empates en cada caso. Si esto es así, los p-valores que se obtienen son buenas aproximaciones de los exactos.

Expresemos la conclusión.
Con 99% confianza, el procedimiento post-hoc no encuentra diferencias significativas en la calidad de las mejores soluciones obtenidas entre las versiones B y C del algoritmo (p>0,038
), pero estas soluciones son de peor calidad (más lejanas a la solución óptima) que las que consigue la versión A (p<0,003
) al resolver las mismas instancias del problema del vendedor viajero con 100 o más nodos.